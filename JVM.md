# 1. 内存模型



## 程序计数器

​		程序计数器（Program Counter Register）是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是**通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需 要依赖这个计数器来完成**。

​		由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的， 在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）都只会执行一条线 程中的指令。因此，**为了线程切换后能恢复到正确的执行位置**，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储，我们称这类内存区域为==**“线程私有”**==的内存。

​		如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指 令的地址；如果正在执行的是Native方法，这个计数器值则为空（Undefined）。此内存区域是**唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域**。



## 虚拟机栈

​		与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是==**线程私有**==的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时 都会创建一个**栈帧（Stack Frame ）**用于**存储局部变量表、操作数栈、动态链接、方法出口**等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出 栈的过程。

​		经常有人把Java内存区分为堆内存（Heap）和栈内存（Stack），这种分法比较粗糙，Java内存区域的划分实际上远比这复杂。这种划分方式的流行只能说明大多数程序员最 关注的、与对象内存分配关系最密切的内存区域是这两块。其中所指的“堆”笔者在后面会专 门讲述，而所指的“栈”就是现在讲的虚拟机栈，或者说是虚拟机栈中局部变量表部分。

​		**局部变量表**存放了编译期可知的各种**基本数据类型**（boolean、byte、char、short、int、 float、long、double）、**对象引用**（reference类型，它不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和 returnAddress类型（指向了一条字节码指令的地址）。

​		其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这 个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变 量表的大小。

​		在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出**StackOverflowError**异常；如果虚拟机栈可以动态扩展（当前大部 分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），如 果扩展时无法申请到足够的内存，就会抛出**OutOfMemoryError**异常。



## 本地方法栈

​		本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用是非常相似的，它们之间 的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚 拟机使用到的Native方法服务。

​		在虚拟机规范中对本地方法栈中方法使用的语言、使用方式 与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如 Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法 栈区域也会抛出StackOverflowError和OutOfMemoryError异常。



## 堆

​		对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中**最大**的一块。 Java堆是被所有==**线程共享**==的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是==**存放对象实例**==，几乎所有的对象实例都在这里分配内存。这一点在Java虚拟机规范中的描述是：所有的对象实例以及数组都要在堆上分配 ，但是随着JIT编译器的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化发生，所有的对象都分配在堆上也渐渐变得不是那么“绝对”了。

​		Java堆是**垃圾收集器管理的主要区域**，因此很多时候也被称做“GC堆”。从内存回收的角度来看，由于现在收集器基本都采用**分代收集**算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点的有 Eden空间、From Survivor空间、To Survivor空间等。从内存分配的角度来看，线程共享的 Java堆中可能划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer,TLAB）。不过无论如何划分，都与存放内容无关，无论哪个区域，存储的都仍然是对象实例，进一步划分的目的是为了更好地回收内存，或者更快地分配内存。

​		根据Java虚拟机规范的规定，Java堆可以处于**物理上不连续**的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照**可扩展**来实现的（通过-Xmx和-Xms控制）。如 果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出**OutOfMemoryError**异 常。



## 方法区

​		方法区（Method Area）与Java堆一样，是各个==**线程共享**==的内存区域，它用于存储==**已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据**==。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应 该是与Java堆区分开来。

​		对于习惯在HotSpot虚拟机上开发、部署程序的开发者来说，很多人都更愿意把方法区 称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的 设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已，这样 HotSpot的垃圾收集器可以像管理Java堆一样管理这部分内存，能够省去专门为方法区编写内 存管理代码的工作。对于其他虚拟机（如BEA JRockit、IBM J9等）来说是不存在永久代的概 念的。原则上，如何实现方法区属于虚拟机实现细节，不受虚拟机规范约束，但使用永久代 来实现方法区，现在看来并不是一个好主意，因为这样更容易遇到内存溢出问题（永久代 有-XX：MaxPermSize的上限，J9和JRockit只要没有触碰到进程可用内存的上限，例如32位系 统中的4GB，就不会出现问题），而且有极少数方法（例如String.intern（））会因这个原因 导致不同虚拟机下有不同的表现。因此，对于HotSpot虚拟机，根据官方发布的路线图信 息，现在也有放弃永久代并逐步改为采用Native Memory来实现方法区的规划了 ，在目前已 经发布的JDK 1.7的HotSpot中，已经把原本放在永久代的字符串常量池移出。

​		Java虚拟机规范对方法区的限制非常宽松，除了和Java堆一样不需要连续的内存和可以 选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个 区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这区 域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说，这个区域的回 收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确 实是必要的。在Sun公司的BUG列表中，曾出现过的若干个严重的BUG就是由于低版本的 HotSpot虚拟机对此区域未完全回收而导致内存泄漏。

​		根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出 **OutOfMemoryError**异常。



## 元空间（JDK 1.8）

​		方法区只是一种虚拟机规范。

​		JDK 1.7 及以前HotSpot用永久代实现方法区，从1.7开始去永久代化（可以认为方法区开始分裂）。

​		JDK 1.8元空间的出现就是为了解决突出的类和类加载器元数据过多导致的OOM问题，因为永久代的大小是在启动时固定好的——很难进行调优。

​		JDK 1.7中开始永久代经过对方法区的分裂后已经几乎只存储类和类加载器的元数据信息了，到了jdk8，元空间中也是存储这些信息，而符号引用、字符串常量等存储位置与jdk7一致，还是“分裂”的方法区

> 符号引用在native heap
>
> 类和类加载器的元数据信息在元空间
>
> 字面量、静态变量、字符串常量在堆

​		所以JDK8忽略了PermSize和MaxPermSize这两个参数，改成了：

-XX:MetaspaceSize=64M：设置元数据空间初始大小（取代-XX:PermSize）和

-XX:MaxMetaspaceSize=128M：设置元数据空间最大值（取代之前-XX:MaxPermSize），

并且再也看不到java.lang.OutOfMemoryError: PermGen error的异常了。



# 2. GC



## 垃圾识别：

​		什么是垃圾：内存中不在被使用到的空间就是垃圾

​		判断对象时垃圾的方法：

### 1. 引用计数法（JVM 不使用）

​		一个对象被引用其引用值就+1，取消引用就-1，很难解决循环引用的问题

### 2. 可达性分析法（JVM 使用）

​		根搜索算法的基本思路就是通过一系列名为”GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。这个算法的基本思想是通过一系列称为“GC Roots”的对象作为起始点，从这些节点向下搜索**（会引起Stop The World）**，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链（即GC Roots到对象不可达）时，则证明此对象是不可用的。

![img](https://img-blog.csdnimg.cn/20190506204803732.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NjI1NzU3,size_16,color_FFFFFF,t_70)


哪些对象可以作为GC Roots

虚拟机栈（栈帧中的局部变量区，也叫做局部变量表）中引用的对象。
方法区中的类静态属性引用的对象。
方法区中常量引用的对象。
本地方法栈中JNI(Native方法)引用的对象。



## 垃圾回收：

 ==JVM采用 **“分代收集”**（Generational Collection）算法==

==**新生代**对象存活率低，有老年代给它担保，一般使用复制算法==

==**老年代**对象存活率高，没有额外空间对它进行分配担保，一般是由标记清除或者是标记清除（多次）与标记整理（一次）的混合实现==



+ 回收过程

> ​		即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，要真正宣告一个对象死亡，至少要经历==**两次标记过程**==：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被**第一次标记**并且进行一次筛选， 筛选的条件是此对象是否有必要执行finalize（）方法。当对象没有覆盖finalize（）方法，或 者finalize（）方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。
>
> ​		如果这个对象被判定为有必要执行finalize（）方法，那么这个对象将会放置在一个叫做 F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，这样做 的原因是，如果一个对象在finalize（）方法中执行缓慢，或者发生了死循环（更极端的情况），将很可能会导致F-Queue队列中其他对象永久处于等待，甚至导致整个内存回收系统 崩溃。finalize（）方法是对象逃脱死亡命运的最后一次机会。
>
> ​		稍后GC将对F-Queue中的对象进行**第二次小规模的标记**，如果对象要在finalize（）中成功拯救自己——只要重新与引用链 上的任何一个对象建立关联即可，譬如把自己（this关键字）赋值给某个类变量或者对象的 成员变量，那在第二次标记时它将被移除出“即将回收”的集合；如果对象这时候还没有逃 脱，那基本上它就真的被回收了。从代码清单3-2中我们可以看到一个对象的finalize（）被 执行，但是它仍然可以存活。



+ 回收方法区

> ​		方法区中进行垃圾收集 的“性价比”一般比较低：在堆中，尤其是在新生代中，常规应用进行一次垃圾收集一般可以 回收70%～95%的空间，而永久代的垃圾收集效率远低于此
>
> 1. **收集废弃常量**
>
>    ​		回收废弃常量与回收 Java堆中的对象非常类似。以常量池中字面量的回收为例，假如一个字符串“abc”已经进入了 常量池中，但是当前系统没有任何一个String对象是叫做“abc”的，换句话说，就是没有任何 String对象引用常量池中的“abc”常量，也没有其他地方引用了这个字面量，如果这时发生内 存回收，而且必要的话，这个“abc”常量就会被系统清理出常量池。常量池中的其他类（接 口）、方法、字段的符号引用也与此类似。
>
> 2. **收集无用的类**
>
>    类需要同时满足下面3个条件才能算是“无用的类”：
>
>    + 该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例。
>
>    + 加载该类的ClassLoader已经被回收。
>
>    + 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。
>
>    虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是 和对象一样，不使用了就必然会回收。是否对类进行回收，HotSpot虚拟机提供了-Xnoclassgc 参数进行控制，还可以使用-verbose：class以及-XX：+TraceClassLoading、-XX： +TraceClassUnLoading查看类加载和卸载信息，其中-verbose：class和-XX： +TraceClassLoading可以在Product版的虚拟机中使用，-XX：+TraceClassUnLoading参数需要 FastDebug版的虚拟机支持。
>
>    在大量使用反射、动态代理、CGLib等ByteCode框架、动态生成JSP以及OSGi这类频繁 自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。



### 1. 引用计数法（JVM 不使用）

+ 什么是引用计数法？
         	 所谓的引用计数法就是给每个对象一个引用计数器，每当有一个地方引用它时，计数器就会加1；当引用失效时，计数器的值就会减1；任何时刻计数器的值为0的对象就是不可能再被使用的。

      ​		这个引用计数法时没有被Java所使用的，但是python有使用到它。而且最原始的引用计数法没有用到GC Roots。

+ 优点
  1. 可即时回收垃圾：在该方法中，每个对象始终知道自己是否有被引用，当被引用的数值为0时，对象马上可以把自己当作空闲空间链接到空闲链表。

  2. 最大暂停时间短。

  3. 没有必要沿着指针查找

+ 缺点

  1. 计数器值的增减处理非常繁重
  2. 计算器需要占用很多位。
  3. 实现繁琐。
  4. 循环引用无法回收。



### 2. 标记 - 清除算法（老年代）

​		**最基础的收集算法是“标记-清除”（Mark-Sweep）算法，如同它的名字一样，算法分 为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有 被标记的对象，它的标记过程其实在前一节讲述对象标记判定时已经介绍过了。之所以说它 是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。**

> 当堆中的有效内存空间（available memory）被耗尽的时候，就会停止整个程序（也被称为Stop The World），然后进行两项工作，第一项则是标记，第二项则是清除。
>
> **标记：**从引用根节点开始标记所有被引用的对象。标记的过程其实就是遍历所有的GC Roots，然后将所有GC Roots可达的对象标记为存活的对象。
>
> **清除：**遍历整个堆，把未标记的对象清除。

+ 优点

	1. 实现简单

	2. 与保守式GC算法兼容（保守式GC在后面介绍）

	3. 不需要双倍的内存空间。

+ 缺点

  1. **效率比较低**（递归与全堆对象遍历），而且在进行GC的时候，需要停止应用程序，这会导致用户体验非常差劲：一个是效率问题，标记和清除两个过程的效率都不高

  2. **碎片化**：如上图所示，在回收的过程中会产生被细化的分块，到后面，即使堆中分块的总大小够用，但是却因为分块太小而不能执行分配。这种方式清理出来的空闲内存是不连续的(内存碎片)，这点不难理解，我们的死亡对象都是随即的出现在内存的各个角落的，现在把它们清除之后，内存的布局自然会乱七八糟。而为了应付这一点，JVM就不得不维持一个内存的空闲列表，这又是一种开销。而且在分配数组对象的时候，寻找连续的内存空间会不太好找。
  
     标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程 序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾 收集动作。标记—清除算法的执行过程如图3-2所示。
  
  3. **Stop The World**：此算法需要暂停整个应用，会产生内存碎片。用通俗的话解释一下标记/清除算法，就是当程序运行期间，若可以使用的内存被耗尽的时候，GC线程就会被触发并将程序暂停，随后将依旧存活的对象标记一遍，最终再将堆中所有没被标记的对象全部清除掉，接下来便让程序恢复运行。
  
  4. 分配速度：因为分块不是连续的，因此每次分块都要遍历空闲链表，找到足够大的分块，从而造成时间的浪费。
  
  5. 与写时复制技术不兼容：所谓写时复制就是fork的时候，内存空间只引用而不复制，只有当该进程的数据发生变化时，才会将数据复制到该进程的内存空间。这样，当两个进程中的内存数据相同的时候，就能节约大量的内存空间了。而对于标记-清除算法，它的每个对象都有一个标志位来表示它是否被标记，在每一次运行标记-清除算法的时候，被引用的对象都会进行标记操作，这个仅仅标记位的改变，也会变成对象数据的改变，从而引发写时复制的复制过程，与写时复制的初衷就背道而驰了。



### 3. 复制算法（新生代）
+ 什么是复制算法？
        	 复制算法就是将内存空间按容量分成两块。当这一块内存用完的时候，就将还存活着的对象复制到另外一块上面，然后把已经使用过的这一块一次清理掉。这样使得每次都是对半块内存进行内存回收。内存分配时就不用考虑内存碎片等复杂情况，只要移动堆顶的指针，按顺序分配内存即可，实现简单，运行高效。
          
     新生代分为一块Eden区和两块Survivor区（8 : 1 : 1）当一个对象创建的时候先进入的是Eden区。

> ​		Survivor区，一块叫From，一块叫To，对象存在Eden和From块。当进行GC时，Eden存活的对象全移到To块，而From中，存活的对象按年龄值确定去向，当达到一定值（年龄阈值，通过-XX:MaxTenuringThreshold可设置，默认15）的对象会移到年老代中，没有达到值的复制到To区，经过GC后，Eden和From被清空。（To区空间不够会找老年代作担保）
>
> ​		之后，From和To交换角色，新的From即为原来的To块，新的To块即为原来的From块，且新的To块中对象年龄加1。
>
> ​		如果在Survivor空间中相同年龄所有对象大小的总 和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等 到MaxTenuringThreshold中要求的年龄

+  担保机制

> ​		虚拟机会检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果成立，那么Minor GC可以确保是安全的。如果不成立，则虚拟机会查看**HandlePromotionFailure**设置值是否允许担保失败。
>
> ​		如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的**平均大小**，如果大于，将尝试着进行一次Minor GC，尽管这次Minor GC是有风险的；如果小于，或者HandlePromotionFailure设置不允许冒险，那这时也要改为进行一次Full GC。
>
> ​		如果某次Minor GC存活后的对象突增，远远高于平均值的话，依然会导致担保失败（Handle Promotion Failure）， 那就只好在失败后重新发起一次Full GC。
>
> ​		大部分情况下会将HandlePromotionFailure开关打开，避免Full GC过于频繁

+ 优点
  1. 优秀的吞吐量，效率高，解决了标记的效率问题
  2. 复制算法**不会产生内存碎片**。
  3. 可实现高速分配：复制算法不用使用空闲链表。这是因为分块是连续的内存空间，因此，调用这个分块的大小，只需要这个分块大小不小于所申请的大小，移动指针进行分配即可。
  4. 与缓存兼容。
+ 缺点
  1. 堆的使用效率低下。（**浪费空间**）它浪费了一半的内存
  2. 不兼容保守式GC算法。
  3. 递归调用函数。



### 4. 标记 - 整理算法（老年代）

​		**标记过程 仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存 活的对象都向一端移动，然后直接清理掉端边界以外的内存**

+ 优点
  1. 解决了标记清理算法的空间碎片化问题
+ 缺点
  1. 效率还是低







## Stop The World：

从GC Roots节点找引用链，要逐个检查这里面的引用，那么必然会消耗很多时间。

这项分析工作必须在一 个能确保一致性的快照中进行（**Stop The World）**

主流Java虚拟机使用的都是**准确式GC**

> ​		当执行系统停顿下来后，并不需要一个不漏地检查完所有 执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放着对象引用。
>
> ​		在 HotSpot的实现中，是使用一组称为**OopMap**的数据结构来达到这个目的的，在类加载完成的 时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在JIT编译过程中，也会在**特定的位置**记录下栈和寄存器中哪些位置是引用。这样，GC在扫描时就可以直接得知 这些信息了。



### 1. 安全点（OopMap）

> ​		导致OopMap内容变化的指令非常多，如果为每一条指令都生成对应的OopMap，那将会需要大量的额外空间，这样GC的空间成本将会变得很高。
>
> ​		HotSpot也没有为每条指令都生成OopMap，只是在“特定的位置”记录了这些信息，这些位置称为**安全点（Safepoint）**，即程序执行时，==**只有在到达安全点时才能暂停**==。
>
> + Safepoint的选定不能太少以致于让 GC等待时间太长
>
> + 也不能过于频繁以致于过分增大运行时的负荷
>
> ​        安全点的选定基本上是以程序“是否具有让程序长时间执行的特征”为标准进行选定的，“长时间 执行”的最明显特征就是指令序列复用，例如方法调用、循环跳转、异常跳转等，所以具有这些功能的指令才会产生Safepoint。
>
> ​		如何在GC发生时让所有线程（这里不包括执行 JNI调用的线程）都“跑”到最近的安全点上再停顿下来？
>
> + 抢先式中断（Preemptive Suspension）
>
> 其中抢先式中断不需 要线程的执行代码主动去配合，在GC发生时，首先把所有线程全部中断，如果发现有线程 中断的地方不在安全点上，就恢复线程，让它“跑”到安全点上。现在几乎没有虚拟机实现采 用抢先式中断来暂停线程从而响应GC事件。
>
> + 和主动式中断（Voluntary Suspension）
>
> ​		而主动式中断的思想是当GC需要中断线程的时候，不直接对线程操作，仅仅简单地设 置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起。 轮询标志的地方和安全点是重合的，另外再加上创建对象需要分配内存的地方。下面代码清 单3-4中的test指令是HotSpot生成的轮询指令，当需要暂停线程时，虚拟机把0x160100的内存 页设置为不可读，线程执行到test指令时就会产生一个自陷异常信号，在预先注册的异常处 理器中暂停线程实现等待，这样一条汇编指令便完成安全点轮询和触发线程中断。



### 2. 安全区

> ​		线程处 于Sleep状态或者Blocked状态，这时候线程无法响应JVM的中断请求，“走”到安全的地方去 中断挂起，JVM也显然不太可能等待线程重新被分配CPU时间。对于这种情况，就需要安全 区域（Safe Region）来解决。
>
> ​		**安全区域是指在一段代码片段之中，引用关系不会发生变化**。在这个区域中的任意地方 开始GC都是安全的。我们也可以把Safe Region看做是被扩展了的Safepoint。
>
> ​		在线程执行到Safe Region中的代码时，首先标识自己已经进入了Safe Region，在这段时间里JVM要发起GC时，就不用管标识自己为Safe Region状态的线程了。在线程要离 开Safe Region时，它要检查系统是否已经完成了根节点枚举（或者是整个GC过程），如果完成了，那线程就继续执行，否则它就必须等待直到收到可以安全离开Safe Region的信号为止。



### 3. 什么时候会STW（进入安全点）

- Garbage collection pauses（垃圾回收）
- JIT相关，比如Code deoptimization, Flushing code cache
- Class redefinition (e.g. javaagent，AOP代码植入的产生的instrumentation)
- Biased lock revocation 取消偏向锁
- Various debug operation (e.g. thread dump or deadlock check) dump 线程



## GC收集器：



### 1. Parallel Scavenge

> ​		Parallel Scavenge收集器是一个==**新生代**==收集器，它也是使用**==复制算法==**的收集器，又是==**并行的多线程**==收集器……看上去和ParNew都一样，那它有什么特别之处呢？
>
> ​		Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，==**CMS等收集器的关注点 是尽可能地缩短垃圾收集时用户线程的停顿时间**，而**Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量**==（Throughput）。所谓吞吐量就是CPU用于运行用户代码的时间与CPU总 消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。
>
> ​		停顿时间越短就越**适合需要与用户交互的程序**，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不 需要太多交互的任务。
>
> ​		Parallel Scavenge收集器提供了**两个参数用于精确控制吞吐量**，分别是控制最大垃圾收集停顿时间的-XX：MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX：GCTimeRatio参 数。
>
> ​		MaxGCPauseMillis参数允许的值是一个大于0的毫秒数，收集器将尽可能地保证内存回 收花费的时间不超过设定值。不过大家不要认为如果把这个参数的值设置得稍小一点就能使 得系统的垃圾收集速度变得更快，GC停顿时间缩短是以牺牲吞吐量和新生代空间来换的：系统把新生代调小一些，收集300MB新生代肯定比收集500MB快吧，这也直接导致垃圾 收集发生得更频繁一些，原来10秒收集一次、每次停顿100毫秒，现在变成5秒收集一次、每 次停顿70毫秒。停顿时间的确在下降，但吞吐量也降下来了。
>
> ​		GCTimeRatio参数的值应当是一个大于0且小于100的整数，也就是垃圾收集时间占总时 间的比率，相当于是吞吐量的倒数。如果把此参数设置为19，那允许的最大GC时间就占总 时间的5%（即1/（1+19）），默认值为99，就是允许最大1%（即1/（1+99））的垃圾收集 时间。
>
> ​		由于与吞吐量关系密切，Parallel Scavenge收集器也经常称为**“吞吐量优先”收集器**。除上 述两个参数之外，Parallel Scavenge收集器还有一个参数-XX：+UseAdaptiveSizePolicy值得关 注。这是一个开关参数，当这个参数打开之后，就不需要手工指定新生代的大小（-Xmn）、 Eden与Survivor区的比例（-XX：SurvivorRatio）、晋升老年代对象年龄（-XX： PretenureSizeThreshold）等细节参数了，虚拟机会**根据当前系统的运行情况收集性能监控信息，动态调整这些参数**以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC 自适应的调节策略（GC Ergonomics） 。如果读者对于收集器运作原来不太了解，手工优化存在困难的时候，使用Parallel Scavenge收集器配合自适应调节策略，把内存管理的调优任务 交给虚拟机去完成将是一个不错的选择。只需要把基本的内存数据设置好（如-Xmx设置最大 堆），然后使用MaxGCPauseMillis参数（更关注最大停顿时间）或GCTimeRatio（更关注吞 吐量）参数给虚拟机设立一个优化目标，那具体细节参数的调节工作就由虚拟机完成了。自 适应调节策略也是Parallel Scavenge收集器与ParNew收集器的一个重要区别。



### 2. Parallel Old

> ​		Parallel Old是Parallel Scavenge收集器的==**老年代**==版本，使用==**多线程**==和==**“标记-整理”**==算法。 这个收集器是在JDK 1.6中才开始提供的。
>
> ​		在此之前，新生代的Parallel Scavenge收集器一直 处于比较尴尬的状态。原因是，如果新生代选择了Parallel Scavenge收集器，老年代除了 Serial Old（PS MarkSweep）收集器外别无选择（还记得上面说过Parallel Scavenge收集器无 法与CMS收集器配合工作吗？）。由于老年代Serial Old收集器在服务端应用性能上的“拖累”，使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果，由于 单线程的老年代收集中无法充分利用服务器多CPU的处理能力，在老年代很大而且硬件比较 高级的环境中，这种组合的吞吐量甚至还不一定有ParNew加CMS的组合“给力”。
>
> ​		直到Parallel Old收集器出现后，==**“吞吐量优先”收集器**==终于有了比较名副其实的应用组合，在注重吞吐量以及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old 收集器。Parallel Old收集器的工作过程如图3-9所示。

![image-20200315154024439](/Users/arvin/Library/Application Support/typora-user-images/image-20200315154024439.png)



### 3. CMS收集器

> ​		在JDK 1.5时期，HotSpot推出了一款在强交互应用中几乎可认为有划时代意义的垃圾收集器——**CMS**收 集器（Concurrent Mark Sweep），==**它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作**==。
>
> ​		CMS作为老年代的收集器，却无法与JDK 1.4.0中已经存在的新生代收集器 Parallel Scavenge配合工作（Parallel Scavenge收集器及G1收集器都没有使用传统的GC收集器代码框架，而是另外独立实现，其余几种收集器则共用了部分的框架代码），所以在JDK 1.5中使用CMS来收集老年代的时候，新生代只能选择ParNew或者Serial收集器中的一个。
>
> 
>
> ​		CMS（Concurrent Mark Sweep）收集器是一种以获取==**最短回收停顿**==时间为目标的收集 器。目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重 视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常 符合这类应用的需求。
>
> ​		从名字（包含“Mark Sweep”）上就可以看出，CMS收集器是基于==**“标记—清除”**==算法实现 的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为4个步骤，包括：
>
> + 初始标记（CMS initial mark） ==**（Stop The World）**==
>
>   ​		初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快
>
> + 并发标记（CMS concurrent mark） ==**（耗时最长）**==
>
>   ​		并发标记阶段就是进行GC RootsTracing 的过程
>
> + 重新标记（CMS remark） ==**（Stop The World）**==
>
>   ​		而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。
>
> + 并发清除（CMS concurrent sweep） ==**（耗时最长）**==
>
> ​        由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起 工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。通 过图3-10可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的时间。

![image-20200315164311455](/Users/arvin/Library/Application Support/typora-user-images/image-20200315164311455.png)

> **缺点：**
>
> 1. CMS收集器对CPU资源非常敏感。其实，面向并发设计的程序都对CPU资源比较敏感。 在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资 源）而导致应用程序变慢，总吞吐量会降低。CMS默认启动的回收线程数是（CPU数量 +3）/4，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且 随着CPU数量的增加而下降。但是当CPU不足4个（譬如2个）时，CMS对用户程序的影响就 可能变得很大，如果本来CPU负载就比较大，还分出一半的运算能力去执行收集器线程，就 可能导致用户程序的执行速度忽然降低了50%，其实也让人无法接受。为了应付这种情况， 虚拟机提供了一种称为“增量式并发收集器”（Incremental Concurrent Mark Sweep/i-CMS）的 CMS收集器变种，所做的事情和单CPU年代PC机操作系统使用抢占式来模拟多任务机制的思 想一样，就是在并发标记、清理的时候让GC线程、用户线程交替运行，尽量减少GC线程的 独占资源的时间，这样整个垃圾收集的过程会更长，但对用户程序的影响就会显得少一些， 也就是速度下降没有那么明显。实践证明，增量时的CMS收集器效果很一般，在目前版本 中，i-CMS已经被声明为“deprecated”，即不再提倡用户使用。
>
> 2. CMS收集器无法处理浮动垃圾（Floating Garbage），可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。由于CMS并发清理阶段用户线程还在运行着，伴 随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法 在当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就称为“浮动垃 圾”。也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间 给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进 行收集，需要预留一部分空间提供并发收集时的程序运作使用。在JDK 1.5的默认设置 下，CMS收集器当老年代使用了68%的空间后就会被激活，这是一个偏保守的设置，如果在 应用中老年代增长不是太快，可以适当调高参数-XX：CMSInitiatingOccupancyFraction的值来 提高触发百分比，以便降低内存回收次数从而获取更好的性能，在JDK 1.6中，CMS收集器 的启动阈值已经提升至92%。要是CMS运行期间预留的内存无法满足程序需要，就会出现一 次“Concurrent Mode Failure”失败，这时虚拟机将启动后备预案：临时启用Serial Old收集器来 重新进行老年代的垃圾收集，这样停顿时间就很长了。所以说参数-XX：CM SInitiatingOccupancyFraction设置得太高很容易导致大量“Concurrent Mode Failure”失败，性能 反而降低。
>
> 3. CMS是一款基于“标记—清除”算法实现的收集 器，如果读者对前面这种算法介绍还有印象的话，就可能想到这意味着收集结束时会有大量 空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次Full GC。为了解决这个问题，CMS收集器提供了一个-XX：+UseCMSCompactAtFullCollection开 关参数（默认就是开启的），用于在CMS收集器顶不住要进行FullGC时开启内存碎片的合并整理过程，内存整理的过程是无法并发的，空间碎片问题没有了，但停顿时间不得不变长。 虚拟机设计者还提供了另外一个参数-XX：CMSFullGCsBeforeCompaction，这个参数是用于 设置执行多少次不压缩的Full GC后，跟着来一次带压缩的（默认值为0，表示每次进入Full GC时都进行碎片整理）。



### 4. G1收集器

> ​		G1是一款面向服务端应用的垃圾收集器。HotSpot希望它未来可以替换掉JDK 1.5中发布的CMS收集器。
>
> + 并行与并发
>
>   ​		G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU（CPU或者 CPU核心）来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的 GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。
>
> + 分代收集
>
>   ​		与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其 他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已 经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。
>
> + 空间整合
>
>   ​		与CMS的“标记—清理”算法不同，G1从**整体**来看是基于**“标记—整理”**算法实现的收集器，从**局部**（两个Region之间）上来看是基于**“复制”**算法实现的，但无论如何，这 两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种 特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一 次GC。
>
> + 可预测的停顿
>
>   ​		这是G1相对于CMS的另一大优势，降低停顿时间是G1和CMS共同的关 注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一 个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实 时Java（RTSJ）的垃圾收集器的特征了。



------



> ​       **分代收集：** 在G1之前的其他收集器进行收集的范围都是整个新生代或者老年代，而G1不再是这 样。使用G1收集器时，Java堆的内存布局就与其他收集器有很大差别，它**将整个Java堆划分为多个大小相等的独立区域**（Region），虽然还保留有新生代和老年代的概念，但**新生代和老年代不再是物理隔离的了**，它们都是一部分Region（不需要连续）的集合。
>
> ​		**可预测的停顿：**G1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java 堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的 空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时 间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。这种使用Region划分 内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高 的收集效率。
>
> ​		**空间整合：**G1把内存“化整为零”的思路，一个细节为例：**把Java堆分为多个Region**后，Region也不可能是孤立的。一个对象分配在某个Region中，它并非只能被本Region中的其他对象引用，而是可以与整个Java堆任意的对象发生引用关系。那在做可达性判定确定对象是否存活的时候，岂不是还得扫描整个Java堆才能保证准确性？这个问题其实并非在G1中才有，只是在G1中更加突出而已。在以前的分代收集中，新生代的规模一般都比老年代要小许多，新生代的收集也比老年代要频繁许多，那回收新生代中的对象时也面临相同的问题，如果回收新生代时也不得不同时扫描老年代的话，那么Minor GC的效率可能下降不少。
>
> ​		在G1收集器中，Region之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，虚拟机都是使用**Remembered Set**来避免全堆扫描的。G1中每个Region都有一个与之对应的Remembered Set，虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个 Write Barrier暂时中断写操作，检查**Reference引用的对象是否处于不同的Region之中**（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过 CardTable把相关引用信息记录到被引用对象所属的Region的Remembered Set之中。当进行内存回收时，在GC根节点的枚举范围中加入Remembered Set即可保证不对全堆扫描也不会有遗漏。
>
> ​		如果不计算维护Remembered Set的操作，G1收集器的运作大致可划分为以下几个步骤： 
>
> + **初始标记（Initial Marking）**
>
>   ​		初始标记阶段仅仅只是标记一下GC Roots能直接关联到的对象，并且修改 TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的 Region中创建新对象，这阶段需要==**停顿线程，但耗时很短**==。
>
> + **并发标记（Concurrent Marking）** 
>
>   ​		并发标记阶段是从GC Root开始 对堆中对象进行可达性分析，找出存活的对象，这阶段==**耗时较长，但可与用户程序并发执行**==。
>
> + **最终标记（Final Marking）** 
>
>   ​		最终标记阶段则是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动 的那一部分标记记录，虚拟机将这段时间对象变化记录在线程Remembered Set Logs里面，最 终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段==**需要停顿线程，但是可并行执行**==。
>
> + **筛选回收（Live Data Counting and Evacuation）** 
>
>   ​		最后在筛选回收阶段首先**对各个Region的回收价值和成本进行排序**， 根据**用户所期望的GC停顿时间**来制定回收计划，从Sun公司透露出来的信息来看，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。通过图3-11可以比较清楚地看到G1收集器的运作步骤中并发和需要停顿的阶段。

![image-20200315165429692](/Users/arvin/Library/Application Support/typora-user-images/image-20200315165429692.png)



# 3. 类加载


​		类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：**加载、验证、准备、解析、初始化**、使用和卸载七个阶段。它们开始的顺序如下图所示：

​		其中类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。
​		这里简要说明下Java中的绑定：**绑定指的是把一个方法的调用与方法所在的类(方法主体)关联起来**，对java来说，绑定分为静态绑定和动态绑定：

​		**静态绑定：**即前期绑定。在程序执行前方法已经被绑定，此时由编译器或其它连接程序实现。针对java，简单的可以理解为程序编译期的绑定。java当中的方法只有final，static，private和构造方法是前期绑定的。
​		**动态绑定：**即晚期绑定，也叫运行时绑定。在运行时根据具体对象的类型进行绑定。在java中，几乎所有的方法都是后期绑定的。

​		Class文件常量池  >>> 运行时常量池

> + **Class文件常量池（Constant Pool Table）**
>
>   ​		存放编译期生成的各种字面量和符号引用
>
> + **运行时常量池（Runtime Constant Pool）**
>
>   ​		方法区的一部分，JDK 1.8 位于元空间，主要存放, class文件元信息描述,编译后的代码，引用类型数据（直接引用），类文件常量池



> + **符号引用（Symbolic References）**
>
>   ​		符号引用以一组符号来描述所引用的目标，符号可 以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的 内存布局无关，引用的目标并不一定已经加载到内存中。各种虚拟机实现的内存布局可以各 不相同，但是它们能接受的符号引用必须都是一致的，因为符号引用的字面量形式明确定义 在Java虚拟机规范的Class文件格式中。
>
> + **直接引用（Direct References）**
>
>   ​		直接引用可以是直接指向目标的指针、相对偏移量或是 一个能间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局相关的，同一个符号引 用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目 标必定已经在内存中存在。





## 加载
​		加载时类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下三件事情：

1. **通过一个类的全限定名来获取其定义的二进制字节流。**

2. **将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。**

3. **在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。**

    > ​		注意，这里第1条中的二进制字节流并不只是单纯地从Class文件中获取，比如它还可以从Jar包中获取、从网络中获取（最典型的应用便是Applet）、由其他文件生成（JSP应用）等。
    >
    > ​		相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。
    >
    > ​		加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个java.lang.Class类的对象，这样便可以通过该对象访问方法区中的这些数据。

​		

**说到加载，不得不提到类加载器，下面就具体讲述下类加载器。**

​		类加载器虽然只用于实现类的加载动作，但它在Java程序中起到的作用却远远不限于类的加载阶段。对于任意一个类，都需要由它的类加载器和这个类本身一同确定其在就Java虚拟机中的唯一性，也就是说，即使两个类来源于同一个Class文件，只要加载它们的类加载器不同，那这两个类就必定不相等。这里的“相等”包括了代表类的Class对象的equals（）、isAssignableFrom（）、isInstance（）等方法的返回结果，也包括了使用instanceof关键字对对象所属关系的判定结果。



**站在Java虚拟机的角度来讲，只存在两种不同的类加载器：**

+ **启动类加载器**

  ​		它使用C++实现（这里仅限于Hotspot，也就是JDK1.5之后默认的虚拟机，有很多其他的虚拟机是用Java语言实现的），是虚拟机自身的一部分。

+ **所有其他的类加载器**

  ​		这些类加载器都由Java语言实现，独立于虚拟机之外，并且全部继承自抽象类 `java.lang.ClassLoader`，这些类加载器需要由启动类加载器加载到内存中之后才能去加载其他的类。



**站在Java开发人员的角度来看，类加载器可以大致划分为以下三类：**

+ 启动类加载器：Bootstrap ClassLoader

  跟上面相同。它负责加载存放在JDK\jre\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库（如rt.jar，所有的java.*开头的类均被Bootstrap ClassLoader加载）。启动类加载器是无法被Java程序直接引用的。*

+ 扩展类加载器：Extension ClassLoader

  该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载JDK\jre\lib\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库（如javax.*开头的类），开发者可以直接使用扩展类加载器。

+ 应用程序类加载器：Application ClassLoader

  该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。
  
  

> 应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，我们还可以加入自定义的类加载器。因为JVM自带的ClassLoader只是懂得从本地文件系统加载标准的java class文件，因此如果编写了自己的ClassLoader，便可以做到如下几点：
>
> 1. 在执行非置信代码之前，自动验证数字签名。
>
> 2. 动态地创建符合用户特定需要的定制化构建类。
>
> 3. 从特定的场所取得java class，例如数据库中和网络中。
>
> 事实上当使用Applet的时候，就用到了特定的ClassLoader，因为这时需要从网络上加载java class，并且要检查相关的安全信息，应用服务器也大都使用了自定义的ClassLoader技术。

​    

**这几种类加载器的层次关系如下图所示：**

![img](https://img-blog.csdn.net/20140105211242593)

​		

​		这种层次关系称为类加载器的==**双亲委派模型**==。我们把每一层上面的类加载器叫做当前层类加载器的父加载器，当然，它们之间的父子关系并不是通过继承关系来实现的，而是使用组合关系来复用父加载器中的代码。该模型在JDK1.2期间被引入并广泛应用于之后几乎所有的Java程序中，但它并不是一个强制性的约束模型，而是Java设计者们推荐给开发者的一种类的加载器实现方式。
​		双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。 
​		使用双亲委派模型来组织类加载器之间的关系，有一个很明显的好处，就是Java类随着它的类加载器（说白了，就是它所在的目录）一起具备了一种带有优先级的层次关系，这对于保证Java程序的稳定运作很重要。例如，类java.lang.Object类存放在JDK\jre\lib下的rt.jar之中，因此无论是哪个类加载器要加载此类，最终都会委派给启动类加载器进行加载，这边保证了Object类在程序中的各种类加载器中都是同一个类。



> [深入理解 Tomcat（四）Tomcat 类加载器之为何违背双亲委派模型](https://blog.csdn.net/qq_38182963/article/details/78660779)
>
> [Java类加载机制（讲道理分析的贼牛逼）](https://blog.csdn.net/fengcaho0616/article/details/81147618?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)





## 验证

​		验证的目的是为了确保Class文件中的字节流包含的信息符合当前虚拟机的要求，而且不会危害虚拟机自身的安全。不同的虚拟机对类验证的实现可能会有所不同，但大致都会完成以下四个阶段的验证：

+ **文件格式的验证**

  ​		验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理，该验证的主要目的是保证输入的字节流能正确地解析并存储于方法区之内。经过该阶段的验证后，字节流才会进入内存的方法区中进行存储，后面的三个验证都是基于方法区的存储结构进行的。

+ **元数据验证**

  ​		对类的元数据信息进行语义校验（其实就是对类中的各数据类型进行语法校验），保证不存在不符合Java语法规范的元数据信息。

+ **字节码验证**

  ​		该阶段验证的主要工作是进行数据流和控制流分析，对类的方法体进行校验分析，以保证被校验的类的方法在运行时不会做出危害虚拟机安全的行为。

+ **符号引用验证**

  ​		这是最后一个阶段的验证，它发生在虚拟机将符号引用转化为直接引用的时候（解析阶段中发生该转化，后面会有讲解），主要是对类自身以外的信息（常量池中的各种符号引用）进行匹配性的校验。





## 准备
​		准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意：

1. 这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。

2. 这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。

   假设一个类变量的定义为：

```java
public static int value = 3；
```

​		那么变量value在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何Java方法，而把value赋值为3的putstatic指令是在程序编译后，存放于类构造器<clinit>（）方法之中的，所以把value赋值为3的动作将在初始化阶段才会执行。



**这里还需要注意如下几点：**

​		对基本数据类型来说，对于类变量（static）和全局变量，如果不显式地对其赋值而直接使用，则系统会为其赋予默认的零值，而对于局部变量来说，在使用前必须显式地为其赋值，否则编译时不通过。
​		对于同时被static和final修饰的常量，必须在声明的时候就为其显式地赋值，否则编译时不通过；而只被final修饰的常量则既可以在声明时显式地为其赋值，也可以在类初始化时显式地为其赋值，总之，在使用前必须为其显式地赋值，系统不会为其赋予默认零值。
​		对于引用数据类型reference来说，如数组引用、对象引用等，如果没有对其进行显式地赋值而直接使用，系统都会为其赋予默认的零值，即null。
​		如果在数组初始化时没有对数组中的各元素赋值，那么其中的元素将根据对应的数据类型而被赋予默认的零值。

3. 如果类字段的字段属性表中存在ConstantValue属性，即同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值。

   假设上面的类变量value被定义为： 

```java
public static final int value = 3；
```

​		编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为3。回忆上一篇博文中对象被动引用的第2个例子，便是这种情况。我们可以理解为static final常量在编译期就将其结果放入了调用它的类的常量池中。





## 解析
​		解析阶段是虚拟机将==**常量池中的符号引用转化为直接引用的过程**==。在Class类文件结构一文中已经比较过了符号引用和直接引用的区别和关联，这里不再赘述。前面说解析阶段可能开始于初始化之前，也可能在初始化之后开始，虚拟机会根据需要来判断，到底是在类被加载器加载时就对常量池中的符号引用进行解析（初始化之前），还是等到一个符号引用将要被使用前才去解析它（初始化之后）。
​		对同一个符号引用进行多次解析请求时很常见的事情，虚拟机实现可能会对第一次解析的结果进行缓存（在运行时常量池中记录直接引用，并把常量标示为已解析状态），从而避免解析动作重复进行。
​		解析动作主要针对**类或接口、字段、类方法、接口方法**四类符号引用进行，分别对应于常量池中的CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info、CONSTANT_InterfaceMethodref_info四种常量类型。

1. **类或接口的解析：**判断所要转化成的直接引用是对数组类型，还是普通的对象类型的引用，从而进行不同的解析。
2. **字段解析：**对字段进行解析时，会先在本类中查找是否包含有简单名称和字段描述符都与目标相匹配的字段，如果有，则查找结束；如果没有，则会按照继承关系从上往下递归搜索该类所实现的各个**接口和它们的父接口**，还没有，则按照继承关系从上往下递归搜索其**父类**，直至查找结束，查找流程如下图所示：

   从下面一段代码的执行结果中很容易看出来字段解析的搜索顺序：

```java
class Super{
	public static int m = 11;
	static{
		System.out.println("执行了super类静态语句块");
	}
}


class Father extends Super{
	public static int m = 33;
	static{
		System.out.println("执行了父类静态语句块");
	}
}

class Child extends Father{
	static{
		System.out.println("执行了子类静态语句块");
	}
}

public class StaticTest{
	public static void main(String[] args){
		System.out.println(Child.m);
	}
}
```

> 执行结果如下：
> 执行了super类静态语句块
> 执行了父类静态语句块
> 33
>
> 如果注释掉Father类中对m定义的那一行，则输出结果如下：
> 执行了super类静态语句块
> 11

   

​		另外，很明显这就是上篇博文中的第1个例子的情况，这里我们便可以分析如下：static变量发生在静态解析阶段，也即是初始化之前，此时已经将字段的符号引用转化为了内存引用，也便将它与对应的类关联在了一起，由于在子类中没有查找到与m相匹配的字段，那么m便不会与子类关联在一起，因此并不会触发子类的初始化。
​		最后需要注意：理论上是按照上述顺序进行搜索解析，但在实际应用中，虚拟机的编译器实现可能要比上述规范要求的更严格一些。如果有一个**同名字段同时出现在该类的接口和父类中，或同时在自己或父类的接口中出现，编译器可能会拒绝编译**。如果对上面的代码做些修改，将Super改为接口，并将Child类继承Father类且实现Super接口，那么在编译时会报出如下错误：
StaticTest.java:24: 对 m 的引用不明确，Father 中的 变量 m 和 Super 中的 变量 m
都匹配

```java
System.out.println(Child.m);
                     ^
```



3. **类方法解析：**对类方法的解析与对字段解析的搜索步骤差不多，只是多了判断该方法所处的是类还是接口的步骤，而且对类方法的匹配搜索，是先搜索父类，再搜索接口。
4. **接口方法解析：**与类方法解析步骤类似，知识接口不会有父类，因此，只递归向上搜索父接口就行了。





## 初始化

​		初始化是类加载过程的最后一步，到了此阶段，才真正开始执行类中定义的Java程序代码。在准备阶段，类变量已经被赋过一次系统要求的初始值，而在初始化阶段，则是根据程序员通过程序指定的主观计划去初始化类变量和其他资源，或者可以从另一个角度来表达：初始化阶段是执行类构造器 `<clinit>()` 方法的过程。
这里简单说明下 `<clinit>()` 方法的执行规则:

1. `<clinit>()` 方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句中可以赋值，但是不能访问。
2. `<clinit>()` 方法与实例构造器 `<clinit>()` 方法（类的构造函数）不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的 `<clinit>()` 方法执行之前，父类的 `<clinit>()` 方法已经执行完毕。因此，在虚拟机中第一个被执行的 `<clinit>()` 方法的类肯定是java.lang.Object。
3. `<clinit>()` 方法对于类或接口来说并不是必须的，如果一个类中没有静态语句块，也没有对类变量的赋值操作，那么编译器可以不为这个类生成 `<clinit>()` 方法。
4. 接口中不能使用静态语句块，但仍然有类变量（final static）初始化的赋值操作，因此接口与类一样会生成`<clinit>()` 方法。但是接口鱼类不同的是：执行接口的 `<clinit>()` 方法不需要先执行父接口的`<clinit>()` 方法，只有当父接口中定义的变量被使用时，父接口才会被初始化。另外，接口的实现类在初始化时也一样不会执行接口的 `<clinit>()` 方法。
5. 虚拟机会保证一个类的 `<clinit>()` 方法在多线程环境中被正确地加锁和同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的 `<clinit>()` 方法，其他线程都需要阻塞等待，直到活动线程执行 `<clinit>()` 方法完毕。如果在一个类的 `<clinit>()` 方法中有耗时很长的操作，那就可能造成多个线程阻塞，在实际应用中这种阻塞往往是很隐蔽的。

下面给出一个简单的例子，以便更清晰地说明如上规则：

```java
class Father{
	public static int a = 1;
	static{
		a = 2;
	}
}

class Child extends Father{
	public static int b = a;
}

public class ClinitTest{
	public static void main(String[] args){
		System.out.println(Child.b);
	}
}
```



> 执行上面的代码，会打印出2，也就是说b的值被赋为了2。

​		首先在准备阶段为类变量分配内存并设置类变量初始值，这样A和B均被赋值为默认值0，而后再在调用 `<clinit>()` 方法时给他们赋予程序中指定的值。当我们调用Child.b时，触发Child的 `<clinit>()` 方法，根据规则2，在此之前，要先执行完其父类Father的 `<clinit>()` 方法，又根据规则1，在执行 `<clinit>()` 方法时，需要按static语句或static变量赋值操作等在代码中出现的顺序来执行相关的static语句，因此当触发执行Father的 `<clinit>()` 方法时，会先将a赋值为1，再执行static语句块中语句，将a赋值为2，而后再执行Child类的 `<clinit>()` 方法，这样便会将b的赋值为2.

​		如果我们颠倒一下Father类中 `public static int a = 1;` 语句和“static语句块”的顺序，程序执行后，则会打印出1。很明显是根据规则1，执行Father的 `<clinit>()` 方法时，根据顺序先执行了static语句块中的内容，后执行了 `public static int a = 1;` 语句。

​		另外，在颠倒二者的顺序之后，如果在static语句块中对a进行访问（比如将a赋给某个变量），在编译时将会报错，因为根据规则1，它**只能对a进行赋值，而不能访问**。

**总结：**

​		整个类加载过程中，除了在加载阶段用户应用程序可以自定义类加载器参与之外，其余所有的动作完全由虚拟机主导和控制。到了初始化才开始执行类中定义的Java程序代码（亦及字节码），但这里的执行代码只是个开端，它仅限于 `<clinit>()` 方法。类加载过程中主要是将Class文件（准确地讲，应该是类的二进制字节流）加载到虚拟机内存中，真正执行字节码的操作，在加载完成后才真正开始。



# 4. 内存中的对象



## 对象的创建方式

+ 指针碰撞（Bump the Pointer）

  ​		假设Java堆中内存是绝对规整的，所有用过的内 存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配 内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离。

+ 空闲列表（Free List）

  ​		如果Java堆中的内存并不是规整的，已使用的内存和空 闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记 录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例， 并更新列表上的记录。

> 选择哪种分配方式由 Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决 定。因此，在使用Serial、ParNew等带Compact过程的收集器时，系统采用的分配算法是指针 碰撞，而使用CMS这种基于Mark-Sweep算法的收集器时，通常采用空闲列表。





## 对象的内存布局

### 1. 对象头（Header）

​		HotSpot虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据， 如**哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳**等，这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为**32bit**和 **64bit**，官方称它为==**“Mark Word”**==。对象需要存储的运行时数据很多，其实已经超出了32位、 64位Bitmap结构所能记录的限度，但是对象头信息是与对象自身定义的数据无关的额外存储 成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的 空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。

> 在32位的 HotSpot虚拟机中，如果对象处于未被锁定的状态下，那么Mark Word的32bit空间中的25bit用 于存储对象哈希码，4bit用于存储对象分代年龄，2bit用于存储锁标志位，1bit固定为0，而在 其他状态（轻量级锁定、重量级锁定、GC标记、可偏向）下对象的存储内容见表。

![image-20200316144647204](/Users/arvin/Library/Application Support/typora-user-images/image-20200316144647204.png)

​		对象头的另外一部分是==**类型指针**==，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说，查找对象的元数据信息并不一定要经过对象本身。 另外，如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中却无法确定数组的大小。



### 2. 实例数据（Instance Data）

​		实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。这部分的**存储顺序**会受到虚拟机分配策略参数（FieldsAllocationStyle）和字段在Java源码中定义顺序的影响。HotSpot虚拟机默认的分配策略为longs/doubles、ints、shorts/chars、 bytes/booleans、oops（Ordinary Object Pointers），从分配策略中可以看出，**相同宽度的字段总是被分配到一起**。在满足这个前提条件的情况下，**在父类中定义的变量会出现在子类之 前**。如果CompactFields参数值为true（默认为true），那么子类之中较窄的变量也可能会插入到父类变量的空隙之中。



### 3. 对齐填充（Padding）

​		对齐填充并不是必然存在的，它仅仅起着占位符的作用。 由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍。而对象头部分正好是8字节的倍数（1倍或者2倍）， 因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。



# 5. 并发 & 锁



## 内存交互协议

​		关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了以下8种操作来 完成，虚拟机实现时必须保证下面提及的每一种操作都是**原子**的、不可再分的（对于double 和long类型的变量来说，load、store、read和write操作在某些平台上允许有例外）。

> 允许虚拟机实现选择可以不保证64位数据类型的load、store、read和write这4个操作的 原子性，这点就是所谓的long和double的非原子性协定

+ lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。

+ unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放 后的变量才可以被其他线程锁定。

+ read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内 存中，以便随后的load动作使用。

+ load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工 作内存的变量副本中。

+ use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引 擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。

+ assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内 存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。

+ store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存 中，以便随后的write操作使用。

+ write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入 主内存的变量中。

​		如果要把一个变量从主内存复制到工作内存，那就要顺序地执行read和load操作，如果 要把变量从工作内存同步回主内存，就要顺序地执行store和write操作。注意，Java内存模型 只要求上述两个操作必须按顺序执行，而没有保证是连续执行。也就是说，read与load之 间、store与write之间是可插入其他指令的，如对主内存中的变量a、b进行访问时，一种可能 出现顺序是read a、read b、load b、load a。除此之外，Java内存模型还规定了在执行上述8种 基本操作时必须满足如下规则：

1. **不允许read和load、store和write操作之一单独出现**，即不允许一个变量从主内存读取了 但工作内存不接受，或者从工作内存发起回写了但主内存不接受的情况出现。
2. 不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。
3. 不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步 回主内存中。
4.  一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化 （load或assign）的变量，换句话说，就是对一个变量实施use、store操作之前，必须先执行 过了assign和load操作。
5. 一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线 程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。
6. 如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这 个变量前，需要重新执行load或assign操作初始化变量的值。
7. 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去 unlock一个被其他线程锁定住的变量。
8. 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操 作）。

​		这8种内存访问操作以及上述规则限定，再加上稍后介绍的对volatile的一些特殊规定， 就已经完全确定了Java程序中哪些内存访问操作在并发下是安全的。由于这种定义相当严谨 但又十分烦琐，实践起来很麻烦，所以在12.3.6节中笔者将介绍这种定义的一个等效判断原 则——**先行发生原则**，用来确定一个访问在并发环境下是否安全。



## volatile 与先行发生

**volatile 的作用：**

+ 保证此变量对所有线程的可见性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以 立即得知的。

+ 禁止指令重排序优化（指令重排序无法越过内存屏障）

> 除了volatile之外，Java还有两个关键字能实现可见性，即synchronized和final。

​		下面是Java内存模型下一些“天然的”先行发生关系，这些先行发生关系无须任何同步器 协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从 下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。

1. **程序次序规则（Program Order Rule）：**在一个线程内，按照程序代码顺序，书写在前面 的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序， 因为要考虑分支、循环等结构。
2. **管程锁定规则（Monitor Lock Rule）：**一个unlock操作先行发生于后面对同一个锁的lock 操作。这里必须强调的是同一个锁，而“后面”是指时间上的先后顺序。
3. **volatile变量规则（Volatile Variable Rule）：**对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序。
4. **线程启动规则（Thread Start Rule）：**Thread对象的start（）方法先行发生于此线程的每 一个动作。
5. **线程终止规则（Thread Termination Rule）：**线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join（）方法结束、Thread.isAlive（）的返回值等手段检测到线程已经终止执行。
6. **线程中断规则（Thread Interruption Rule）：**对线程interrupt（）方法的调用先行发生于被 中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted（）方法检测到是否有中断发生。
7. **对象终结规则（Finalizer Rule）：**一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize（）方法的开始。
8. **传递性（Transitivity）：**如果操作A先行发生于操作B，操作B先行发生于操作C，那就 可以得出操作A先行发生于操作C的结论。





## 状态转换

​		Java语言定义了5种线程状态，在任意一个时间点，一个线程只能有且只有其中的一种 状态，这5种状态分别如下。

1. **新建（New）：**创建后尚未启动的线程处于这种状态。

2. **运行（Runable）：**Runable包括了操作系统线程状态中的Running和Ready，也就是处于此 状态的线程有可能正在执行，也有可能正在等待着CPU为它分配执行时间。 

3. **无限期等待（Waiting）：**处于这种状态的线程不会被分配CPU执行时间，它们要等待被 其他线程显式地唤醒。以下方法会让线程陷入无限期的等待状态：

   + 没有设置Timeout参数的Object.wait（）方法。

     [为什么wait()方法要放在同步块](https://www.cnblogs.com/Joy-Hu/p/10693969.html)
     
   + 没有设置Timeout参数的Thread.join（）方法。

   + LockSupport.park（）方法。

4. **限期等待（Timed Waiting）：**处于这种状态的线程也不会被分配CPU执行时间，不过无 须等待被其他线程显式地唤醒，在一定时间之后它们会由系统自动唤醒。以下方法会让线程 进入限期等待状态

   + Thread.sleep（）方法。
   + 设置了Timeout参数的Object.wait（）方法。
   + 设置了Timeout参数的Thread.join（）方法。
   + LockSupport.parkNanos（）方法。
   + LockSupport.parkUntil（）方法。

5. **阻塞（Blocked）：**线程被阻塞了，**“阻塞状态”与“等待状态”的区别是：“阻塞状态”在等待着获取到一个排他锁**，这个事件将在另外一个线程放弃这个锁的时候发生；而“等待状 态”则是在等待一段时间，或者唤醒动作的发生。在程序等待进入同步区域的时候，线程将 进入这种状态。
6.  **结束（Terminated）：**已终止线程的线程状态，线程已经结束执行。

<img src="/Users/arvin/Library/Application Support/typora-user-images/image-20200316155843233.png" alt="image-20200316155843233" style="zoom:67%;" />





## 互斥同步

### synchronized（管程）

​		synchronized关键字经过编译之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java程序中的 synchronized明确指定了对象参数，那就是这个对象的reference；如果没有明确指定，那就根 据synchronized修饰的是实例方法还是类方法，去取对应的对象实例或Class对象来作为锁对象。

​		在执行monitorenter指令时，首先要尝试获取对象的锁。如果这 个对象没被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加1，相应的，在 执行monitorexit指令时会将锁计数器减1，当计数器为0时，锁就被释放。如果获取对象锁失 败，那当前线程就要阻塞等待，直到对象锁被另外一个线程释放为止。

​		synchronized同步块对同一条线程来说是**可重入**的。



### ReentrantLock（java.util.concurrent）

​		ReentrantLock与synchronized很相似，他们都 具备一样的线程**重入**特性，只是代码写法上有点区别，一个表现为**API层面（AQS）**的互斥锁 （`lock()`和 `unlock()` 方法配合 `try/finally` 语句块来完成），另一个表现为**原生语法层面**的互斥锁。不过，相比synchronized,ReentrantLock增加了一些高级功能，主要有以下3项：

+ 等待可中断 `tryLock()`
+ 可实现公平锁 `new ReentrantLock(false)`
+ 以及锁可以绑定多个条件 `condition`



## 非阻塞同步

### CAS 比较并交换（Compare-and-Swap）

​		在 JDK 1.5之后，Java程序中才可以使用CAS操作，该操作由sun.misc.Unsafe类里面的 compareAndSwapInt（）和compareAndSwapLong（）等几个方法包装提供，虚拟机在内部对 这些方法做了特殊处理，即时编译出来的结果就是一条平台相关的处理器CAS指令，没有方 法调用的过程，或者可以认为是无条件内联进去了。

​		CAS指令需要有3个操作数，分别是内存位置（在Java中可以简单理解为变量的内存地址，用V表示）、旧的预期值（用A表示）和新值（用B表示）。CAS指令执行时，当且仅当V符合旧预期值A时，处理器用新值B更新V的值，否则它就不执行更新，但是无论是否更新 了V的值，都会返回V的旧值，上述的处理过程是一个**原子操作**。

### “ABA” 问题

​		J.U.C包为了解决这个问题， 提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的**版本**来保证CAS的正确性。不过目前来说这个类比较“鸡肋”，大部分情况下ABA问题不会影响程 序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更高效。

### 无同步方案

+ 可重入代码（Reentrant Code）

  ​		不依赖存储在堆上的数据和公用的系统资源、用到 的状态量都由参数中传入、不调用非可重入的方法，返回结果是可以预测的，只要输入了相同的数 据，就都能返回相同的结果

+ 线程本地存储（Thread Local Storage）

  ​		如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行？如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内 `java.lang.ThreadLocal` ，这样，无须同步也能保证线程之间不出 现数据争用的问题。

  > 符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费 者”模式）都会将产品的**消费过程尽量在一个线程中消费完**，其中最重要的一个应用实例就 是经典Web交互模型中的**“一个请求对应一个服务器线程”**（Thread-per-Request）的处理方 式，这种处理方式的广泛应用使得很多Web服务端应用都可以使用线程本地存储来解决线程 安全问题。



## 锁优化

适应性自旋（Adaptive Spinning）、锁消除 （Lock Elimination）、锁粗化（Lock Coarsening）、轻量级锁（Lightweight Locking）和偏向 锁（Biased Locking）



# 6. JVM调优参数



> -X ：非标准选项
>
> -XX：非稳定选项
>
>  
>
> 在选项名前用 “+” 或 “-” 表示开启或关闭特定的选项，例：
>
>   -XX:+UseCompressedOops：表示开启 压缩指针
>
>   -XX:-UseCompressedOops：表示关闭 压缩指针



### 1. 堆分配参数

==-Xmn10M：设置新生代区域大小为10M==

==-XX:NewSize=2M：设置新生代初始大小为2M==

==-XX:MaxNewSize=2M：设置新生代最大值为2M==

> 如果以上三个同时设置了，谁在后面谁生效。生产环境使用-Xmn即可，避免抖动

==-Xms128M：设置java程序启动时堆内存128M（默认为物理内存1/64,且小于1G）==

==-Xmx256M：设置最大堆内存256M，超出后会出现 OutOfMemoryError（默认为物理内存1/64,且小于1G）==

> 生产环境 -Xms 与 -Xmx 最好一样，避免抖动

==-Xss1M：设置线程栈的大小 1M（默认1M）==

-XX:ThreadStackSize，-Xss 设置在后面，以-Xss为准；  -XX:ThreadStackSize设置在后面，主线程以 -Xss为准，其他线程以  -XX:ThreadStackSize为准

-XX:MinHeapFreeRatio=40：设置堆空间最小空闲比例（默认40）（当-Xmx与-Xms相等时，该配置无效）

-XX:MaxHeapFreeRatio=70：设置堆空间最大空闲比例（默认70）（当-Xmx与-Xms相等时，该配置无效）

==-XX:NewRatio=2：设置年轻代与年老代的比例为2:1==

==-XX:SurvivorRatio=8：设置年轻代中eden区与survivor区的比例为8：1==

==-XX:MetaspaceSize=64M：设置元数据空间初始大小（取代-XX:PermSize）==

==-XX:MaxMetaspaceSize=128M：设置元数据空间最大值（取代之前-XX:MaxPermSize）==

-XX:TargetSurvivorRatio=50：设置survivor区使用率。当survivor区达到50%时，将对象送入老年代

-XX:+UseTLAB：在年轻代空间中使用本地线程分配缓冲区(TLAB)，默认开启

-XX:TLABSize=512k：设置TLAB大小为512k

-XX:+UseCompressedOops：使用压缩指针，默认开启



### 2. 垃圾回收器相关

==-XX:MaxTenuringThreshold=15：对象进入老年代的年龄（Parallel是15，CMS是6）==

==-XX:PretenureSizeThreshold：令大于这个设置值的对象直接在老 年代分配==

==HandlePromotionFailure：是否允许担保失败==

-XX:MaxGCPauseMillis：设置最大垃圾收集停顿时间（收集器工作时会调整其他参数大小，尽可能将停顿控制在指定时间内）

-XX:+UseAdaptiveSizePolicy：打开自适应GC策略（该摸式下，各项参数都会被自动调整）

-XX:+UseSerialGC：在年轻代和年老代使用串行回收器


-XX:+UseParallelGC：使用并行垃圾回收收集器，默认会同时启用 -XX:+UseParallelOldGC（默认使用该回收器）

-XX:+UseParallelOldGC：开启老年代使用并行垃圾收集器，默认会同时启用 -XX:+UseParallelGC

-XX:ParallelGCThreads=4：设置用于垃圾回收的线程数为4（默认与CPU数量相同）


-XX:+UseConcMarkSweepGC：使用CMS收集器（年老代）

-XX:CMSInitiatingOccupancyFraction=80：设置CMS收集器在年老代空间被使用多少后触发

-XX:+CMSClassUnloadingEnabled：允许对类元数据进行回收

-XX:+UseCMSInitiatingOccupancyOnly：只在达到阈值的时候，才进行CMS回收


-XX:+UseG1GC：使用G1回收器

-XX:G1HeapRegionSize=16m：使用G1收集器时设置每个Region的大小（范围1M - 32M）

-XX:MaxGCPauseMillis=500 ：设置最大暂停时间（毫秒）


-XX:+DisableExplicitGC：禁止显示GC的调用（即禁止开发者的 System.gc();）

 

### 2. GC日志

==-XX:+PrintGCApplicationStoppedTime 会打出系统停止的时间==

==-XX:+PrintSafepointStatistics -XX:PrintSafepointStatisticsCount=1 这两个参数会打印出详细信息==

-XX:+PrintGCDetails：打印GC信息

-XX:+PrintGCTimeStamps ：打印每次GC的时间戳（现在距离启动的时间长度）

-XX:+PrintGCDateStamps ：打印GC日期

-XX:+PrintHeapAtGC：每次GC时，打印堆信息

-Xloggc:/usr/local/tomcat/logs/gc.$$.log ：GC日志存放的位置



### 3. 堆快照
-XX:+HeapDumpOnOutOfMemoryError：出现内存溢出时存储堆信息，配合 -XX:HeapDumpPath 使用

-XX:HeapDumpPath=/usr/local/tomcat/logs/oom.%t.log：堆快照存储位置

-XX:+UseLargePages：使用大页  

-XX:LargePageSizeInBytes=4m：指定大页的大小（必须为2的幂）



### 4. 滚动日志记录
-XX:+UseGCLogFileRotation  ： 开启滚动日志记录

-XX:NumberOfGCLogFiles=5 ：滚动数量，命名为filename.0, filename.1 .....  filename.n-1,  然后再从filename.0 开始，并覆盖已经存在的文件

-XX:GCLogFileSize=8k  :  每个文件大小，当达到该指定大小时，会写入下一个文件

-Xloggc:/gc/log   ：日志文件位置