# TCP



## 首部（20 字节）

<img src="https://img-blog.csdn.net/20180717201939345?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4OTUwMzE2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img" style="zoom: 67%;" />

+ **序列号seq：**占4个字节，用来标记数据段的顺序，TCP把连接中发送的所有数据字节都编上一个序号，第一个字节的编号由本地随机产生；给字节编上序号后，就给每一个报文段指派一个序号；序列号seq就是这个报文段中的第一个字节的数据编号。

+ **确认号ack：**占4个字节，期待收到对方下一个报文段的第一个数据字节的序号；序列号表示报文段携带数据的第一个字节的编号；而确认号指的是期望接收到下一个字节的编号；因此当前报文段最后一个字节的编号+1即为确认号。

+ **确认ACK：**占1位，仅当ACK=1时，确认号字段才有效。ACK=0时，确认号无效

+ **同步SYN：**连接建立时用于同步序号。当SYN=1，ACK=0时表示：这是一个连接请求报文段。若同意连接，则在响应报文段中使得SYN=1，ACK=1。因此，SYN=1表示这是一个连接请求，或连接接受报文。SYN这个标志位只有在TCP建产连接时才会被置1，握手完成后SYN标志位被置0。    

+ **终止FIN：**用来释放一个连接。FIN=1表示：此报文段的发送方的数据已经发送完毕，并要求释放运输连接

  > ACK、SYN和FIN这些大写的单词表示标志位，其值要么是1，要么是0；ack、seq小写的单词表示序号。

| 字段 |                             含义                             |
| :--: | :----------------------------------------------------------: |
| URG  |       紧急指针是否有效。为1，表示某一位需要被优先处理        |
| ACK  |                 确认号是否有效，一般置为1。                  |
| PSH  |        提示接收端应用程序立即从TCP缓冲区把数据读走。         |
| RST  |                 对方要求重新建立连接，复位。                 |
| SYN  | 请求建立连接，并在其序列号的字段进行序列号的初始值设定。建立连接，设置为1 |
| FIN  |                        希望断开连接。                        |



## 三次握手

<img src="https://img-blog.csdn.net/20180717202520531?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4OTUwMzE2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img" style="zoom:67%;" />

+ **第一次握手：**建立连接时，客户端发送syn包（syn=x）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。

+ **第二次握手：**服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（syn=y），即SYN+ACK包，此时服务器进入SYN_RECV状态；

+ **第三次握手：**客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=y+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。



## 四次挥手

<img src="https://img-blog.csdn.net/20180717204202563?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4OTUwMzE2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img" style="zoom:67%;" />

1. 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。
2. 服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。
3. 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
4. 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
5. 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。
6. 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。



## 常见问题
**【问题1】为什么连接的时候是三次握手，关闭的时候却是四次握手？**

​		因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。

**【问题2】为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？**

​		虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以**TIME_WAIT状态就是用来重发可能丢失的ACK报文**。在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN片段。所以Client不能立即关闭，它必须确认Server接收到了该ACK。Client会在发送出ACK之后进入到TIME_WAIT状态。Client会设置一个计时器，等待2MSL的时间。如果在该时间内再次收到FIN，那么Client会重发ACK并再次等待2MSL。所谓的**2MSL是两倍的MSL(Maximum Segment Lifetime)**。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。

**【问题3】为什么不能用两次握手进行连接？**

​		3次握手完成两个重要的功能，既要双方做好发送数据的准备工作(双方都知道彼此已准备好)，也要允许双方就初始序列号进行协商，这个序列号在握手过程中被发送和确认。

> ​		现在把三次握手改成仅需要两次握手，死锁是可能发生的。
>
> ​		假定C给S发送一个连接请求分组，S收到了这个分组，并发送了确认应答分组。按照两次握手的协定，S认为连接已经成功地建立了，可以开始发送数据分组。可是，C在S的应答分组在传输中被丢失的情况下，将不知道S 是否已准备好，不知道S建立什么样的序列号，C甚至怀疑S是否收到自己的连接请求分组。在这种情况下，C认为连接还未建立成功，将忽略S发来的任何数据分组，只等待连接确认应答分组。而S在发出的分组超时后，重复发送同样的分组。这样就形成了死锁。

**【问题4】如果已经建立了连接，但是客户端突然出现故障了怎么办？**

​		TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为**2小时**，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔**75秒**发送一次。若一连发送**10**个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

==**time_wait状态如何避免**==

首先服务器可以设置SO_REUSEADDR套接字选项来通知内核，如果端口忙，但TCP连接位于TIME_WAIT状态时可以重用端口。在一个非常有用的场景就是，如果你的服务器程序停止后想立即重启，而新的套接字依旧希望使用同一端口，此时SO_REUSEADDR选项就可以避免TIME_WAIT状态。

具体的解决方式

vim /etc/sysctl.conf

net.ipv4.tcp_syncookies = 1

// 表示开启SYN cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭

net.ipv4.tcp_tw_reuse = 1

//表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；

net.ipv4.tcp_tw_recycle = 1

//表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭

net.ipv4.tcp_fin_timeout = 30

//修改系統默认的 TIMEOUT 时间

/sbin/sysctl -p   //保存后生效



## 拥塞控制

发送方为一个动态变化的窗口叫做拥塞窗口，拥塞窗口的大小取决于网络的拥塞程度。发送方让自己的发送窗口=拥塞窗口，但是发送窗口不是一直等于拥塞窗口的，在网络情况好的时候，拥塞窗口不断的增加，发送方的窗口自然也随着增加，但是接受方的接受能力有限，在发送方的窗口达到某个大小时就不在发生变化了。

发送方如果知道网络拥塞了呢？发送方发送一些报文段时，如果发送方没有在时间间隔内收到接收方的确认报文段，则就可以人为网络出现了拥塞。

![img](https://images2018.cnblogs.com/blog/771778/201805/771778-20180501140117870-857538058.png)

### 慢启动

主机开发发送数据报时，如果立即将大量的数据注入到网络中，可能会出现网络的拥塞。慢启动算法就是在主机刚开始发送数据报的时候先探测一下网络的状况，如果网络状况良好，发送方每发送一次文段都能正确的接受确认报文段。那么就从小到大的增加拥塞窗口的大小，即增加发送窗口的大小。

例子：开始发送方先设置cwnd（拥塞窗口）=1,发送第一个报文段M1，接收方接收到M1后，发送方接收到接收方的确认后，把cwnd增加到2，接着发送方发送M2、M3，发送方接收到接收方发送的确认后cwnd增加到4，慢启动算法每经过一个传输轮次（认为发送方都成功接收接收方的确认），拥塞窗口cwnd就加倍。

### 拥塞避免

为了防止cwnd增加过快而导致网络拥塞，所以需要设置一个慢开始门限ssthresh状态变量（我也不知道这个到底是什么，就认为他是一个拥塞控制的标识）,它的用法：

1. 当cwnd < ssthresh,使用慢启动算法，
2. 当cwnd > ssthresh,使用拥塞控制算法，停用慢启动算法。
3. 当cwnd = ssthresh，这两个算法都可以。

拥塞避免的思路：是让cwnd缓慢的增加而不是加倍的增长，每经历过一次往返时间就使cwnd增加1，而不是加倍，这样使cwnd缓慢的增长，比慢启动要慢的多。

无论是慢启动算法还是拥塞避免算法，只要判断网络出现拥塞，就要把慢启动开始门限(ssthresh)设置为设置为发送窗口的一半（>=2），cwnd(拥塞窗口)设置为1，然后在使用慢启动算法，这样做的目的能迅速的减少主机向网络中传输数据，使发生拥塞的路由器能够把队列中堆积的分组处理完毕。拥塞窗口是按照线性的规律增长，比慢启动算法拥塞窗口增长块的多。

实例：
1.TCP连接进行初始化的时候，cwnd=1,ssthresh=16。
2.在慢启动算法开始时，cwnd的初始值是1，每次发送方收到一个ACK拥塞窗口就增加1，当ssthresh =cwnd时，就启动拥塞控制算法，拥塞窗口按照规律增长，
3.当cwnd=24时，网络出现超时，发送方收不到确认ACK，此时设置ssthresh=12,(二分之一cwnd),设置cwnd=1,然后开始慢启动算法，当cwnd=ssthresh=12,慢启动算法变为拥塞控制算法，cwnd按照线性的速度进行增长。

### AIMD(加法增大乘法减小)

1. 乘法减小：无论在慢启动阶段还是在拥塞控制阶段，只要网络出现超时，就是将cwnd置为1，ssthresh置为cwnd的一半，然后开始执行慢启动算法（cwnd<ssthresh）。
2. 加法增大：当网络频发出现超时情况时，ssthresh就下降的很快，为了减少注入到网络中的分组数，而加法增大是指执行拥塞避免算法后，是拥塞窗口缓慢的增大，以防止网络过早出现拥塞。
   这两个结合起来就是AIMD算法，是使用最广泛的算法。拥塞避免算法不能够完全的避免网络拥塞，通过控制拥塞窗口的大小只能使网络不易出现拥塞。

### 快重传

​		快重传算法要求首先接收方收到一个失序的报文段后就立刻发出重复确认，而不要等待自己发送数据时才进行捎带确认。接收方成功的接受了发送方发送来的M1、M2并且分别给发送了ACK，现在接收方没有收到M3，而接收到了M4，显然接收方不能确认M4，因为M4是失序的报文段。如果根据可靠性传输原理接收方什么都不做，但是按照快速重传算法，在收到M4、M5等报文段的时候，不断重复的向发送方发送M2的ACK,如果接收方一连收到三个重复的ACK,那么发送方不必等待重传计时器到期，由于发送方尽早重传未被确认的报文段。

### 快恢复

1. 当发送发连续接收到三个确认时，就执行乘法减小算法，把慢启动开始门限（ssthresh）减半，但是接下来并不执行慢开始算法。
2. 此时不执行慢启动算法，而是把cwnd设置为ssthresh的一半， 然后执行拥塞避免算法，使拥塞窗口缓慢增大。
![img](https://img2018.cnblogs.com/blog/443934/201907/443934-20190718132020300-1269239957.png)



## 流量控制

滑动窗口协议

窗口大小

（接收端向发送端主机通知自己可以接受数据的大小，这个大小限制就叫做窗口大小）

窗口扩大因子M

接收端如何把窗口大小告诉发送端呢? 回忆我们的TCP首部中, 有一个16位窗口字段, 就是存放了窗口大小信息;那么问题来了, 16位数字最大表示65535, 那么TCP窗口最大就是65535字节么?实际上, TCP首部40字节选项中还包含了一个窗口扩大因子M,
实际窗口大小是 窗口字段的值左移 M 位;

机理

接收端将自己可以接收的缓冲区大小放入 TCP 首部中的 “窗口大小” 字段, 通过ACK端通知发送端;窗口大小字段越大, 说明网络的吞吐量越高;
接收端一旦发现自己的缓冲区快满了, 就会将窗口大小设置成一个更小的值通知给发送端;发送端接受到这个窗口之后, 就会减慢自己的发送速度;

如果接收端缓冲区满了, 就会将窗口置为0; 这时发送方不再发送数据, 但是需要定期发送一个窗口探测数据段, 使接收端把窗口大小告诉发送端

如图

当接收端收到从3001号开始的数据段后其缓冲区挤满。不得不暂时停止发送数据，之后窗口收到更新通知后才得以继续进行。如果这个通知在途中丢失了，可能导致无法继续通信。所以发送方会是不是发送一个窗口探测的数据段。此数据端仅含一个字节来获取最新的窗口大小。

<img src="https://img-blog.csdn.net/20180605190737615?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pnZWdl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"  />





# DNS

### DNS解析过程
1. 浏览器检查缓存种有没有这个域名对应的解析过的ip地址，如果有该解析过程将会结束。
2. 检查本地的hosts文件是否有这个网址映射关系
3. 如果hosts种没有这个域名映射，查找本地DNS解析器缓存，如果有直接返回
4. 通过首选DNS服务器(本地域名服务器)，以递归或循环的方式查询域名对应的ip地址并返回。(顶级域，二级域，三级域)

一个详细过程

1. 查询 浏览器、操作系统 缓存。
2. 请求 本地域名服务器
3. 本地域名服务器未命中缓存，其请求 根域名服务器。
4. 根域名服务器返回所查询域的主域名服务器。（主域名、顶级域名，如com、cn）
5. 本地域名服务器请求主域名服务器，获取该域名的 名称服务器（域名注册商的服务器）。
6. 本地域名服务器向 名称服务器 请求 域名-IP 映射。
7. 缓存解析结果



### 什么时候用TCP

dns有两个情况，一种是区域传输，一种是[域名解析](https://www.baidu.com/s?wd=域名解析&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)

1. 区域传输时，一个区中主[DNS服务器](https://www.baidu.com/s?wd=DNS服务器&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)从自己本机的数据文件中读取该区的DNS数据信息，而辅助[DNS服务器](https://www.baidu.com/s?wd=DNS服务器&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)则从区的主[DNS服务器](https://www.baidu.com/s?wd=DNS服务器&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)中读取该区的DNS数据信息，传输协议是tcp。
2. [域名解析](https://www.baidu.com/s?wd=域名解析&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)时，首选的[通讯协议](https://www.baidu.com/s?wd=通讯协议&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)是udp
   使用udp传输，不用经过TCP[三次握手](https://www.baidu.com/s?wd=三次握手&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)，这样DNS服务器负载更低，响应更快
   但是当[域名解析](https://www.baidu.com/s?wd=域名解析&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)的反馈报文的长度超过512字节时，将不能使用[udp协议](https://www.baidu.com/s?wd=udp协议&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)进行解析，此时必须使用tcp



### 迭代和递归

+ 一般客户机和服务器之间为**递归查询** 

客户机会一直查到找到正确的dns服务器并返回结果。



+ 一般服务器与服务器之间为**迭代查询**

客户机发送请求给dns1，dns1不能解析，则dns1把dns2的ip给客户机，客户机自动跳转到dns2，直到查询到为止。





# TCP UDP 区别

+ **TCP的优点** 

​		可靠，稳定 TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源。 

+ **TCP的缺点**

​		慢，效率低，占用系统资源高，易被攻击 TCP在传递数据之前，要先建连接，这会消耗时间，而且在数据传递时，确认机制、重传机制、拥塞控制机制等都会消耗大量的时间，而且要在每台设备上维护所有的传输连接，事实上，每个连接都会占用系统的CPU、内存等硬件资源。 而且，因为TCP有确认机制、三次握手机制，这些也导致TCP容易被人利用，实现DOS、DDOS、CC等攻击。

+ **UDP的优点** 

​		快，比TCP稍安全 UDP没有TCP的握手、确认、窗口、重传、拥塞控制等机制，UDP是一个无状态的传输协议，所以它在传递数据时非常快。没有TCP的这些机制，UDP较TCP被攻击者利用的漏洞就要少一些。但UDP也是无法避免攻击的，比如：UDP Flood攻击…… 

+ **UDP的缺点** 

​		不可靠，不稳定 因为UDP没有TCP那些可靠的机制，在数据传递时，如果网络质量不好，就会很容易丢包。 基于上面的优缺点，

+ **TCP UDP 区别**

  

> **什么时候应该使用TCP：** 
>
> ​		当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。 在日常生活中，常见使用TCP协议的应用如下： 浏览器，用的HTTP FlashFXP，用的FTP Outlook，用的POP、SMTP Putty，用的Telnet、SSH QQ文件传输 ………… 
>
> **什么时候应该使用UDP：** 
>
> ​		当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。 比如，日常生活中，常见使用UDP协议的应用如下： QQ语音 QQ视频 TFTP ……





# Socket

![image-20200318233132262](/Users/arvin/Library/Application Support/typora-user-images/image-20200318233132262.png)

==**connect()函数和accept()函数分别在三次握手第2 , 3次后返回**==

### 服务器端和客户端

对于服务器端的流程——类似于接电话过程

socket()[找到一个可以通话的手机]----->bind()[插入一个固定号码]------>listen()[随时准备接听]-------> accept------->recv()------->send()------>close();

对于客户端的主要流程----类似于打电话过程

socket()----->connect()------>recv/read/send------>close()

### 三个接口函数介绍

1. `connect()` 函数：是一个**阻塞函数**通过TCP三次握手建立连接客户端主动连接服务器，通过TCP三次握手通知Linux内核自动完成TCP 三次握手连接 如果连接成功为0 失败返回值-1，一般的情况下客户端的connect函数，默认是阻塞行为，直到三次握手阶段成功为止。

2. 服务器端的 `listen()`  函数：**不是一个阻塞函数**： 功能：将套接字和套接字对应队列的长度告诉Linux内核。他是被动连接的一直监听来自不同客户端的请求， listen函数将socketfd 变成被动的连接监听socket 其中参数backlog作用设置内核中队列的长度 。

注：listen的函数形式int listen(int sockfd, int backlog); backlog代表listen队列的长度。

3. accept() **函数阻塞**：从处于established 状态的队列中取出完成的连接，当队列中没有完成连接时候，会形成阻塞，直到取出队列中已完成连接的用户连接为止（**Accept默认会阻塞进程，直到有一个客户连接建立后返回**）。

## 对应关系

 在TCP/IP详解中，这三个函数与TCP三次握手之间的对应关系是这样的

- **服务器调用listen进行监听**
- **客户端调用connect来发送syn报文**
- **服务器协议栈负责三次握手的交互过程。连接建立后，往listen队列中添加一个成功的连接，直到队列的最大长度。**
- **服务器调用accept从listen队列中取出一条成功的tcp连接，listen队列中的连接个数就少一个**





# Tomcat启动过程

### server.xml

1. .
2. └── server
3. ├── listener
4. └── service
5. ├── connector
6. ├── engine
7. │ ├── host
8. │ │ └── value
9. │ └── realm
10. └── executor

实际上，这里面的每一个标签代表了tomcat架构中的一个**接口类(interface)**，他们的对应关系：

1. server --> org.apache.catalina.Server
2. service --> org.apache.catalina.Service
3. connector --> org.apache.catalina.connector.Connector
4. engine --> org.apache.catalina.Engine
5. host --> org.apache.catalina.Host
6. realm --> org.apache.catalina.Realm
7. executor --> org.apache.catalina.Executor



### Bootstrap启动

​		tomcat提供了 Bootstrap类作为服务器的命令处理器，由它创建 Catalina实例并根据外部传递的命令控制 Catalina的**启动**和**关闭**。 Bootstrap本身是一个单独的 JAR包被放到 $CATALINA_HOME/bin目录下面。而从上面的源码中会看到， Bootstrap总是通过Java的反射操作 Catalina，因为启动服务器这个过程对运行时没有多大的影响，这种方式实现了程序启动和服务核心代码的**解耦**。

​		而这种解耦带来的另外一个优势是tomcat在这一步，可以灵活地定制自己的类加载器，根据 servlet规范每一个Web应用都有独立的**类加载器实例**。

​		再回到 Catalina，它通过 Digester框架(XML解析框架)**定义转换规则**，将 server.xml中的配置标签都转换成对应的类实例，一个 tomcat程序这样就启动完毕了。



### 总结

​		tomcat的开发严格遵守了面向接口开发的设计规范，其软件的**架构设计**，**启动的方式**，**配置文件的读取方式**都非常值得我们借鉴到我们自己的系统平台中，我觉得能把握好**微观的设计**，才能做出更好的平台系统，正像 @左耳朵耗子 陈皓老师在博客中说的: "如果你要做好架构，首先你得把计算机体系结构以及很多老古董的基础技术吃透了。"





# NIO

#### 高并发量引起的问题

使用传统阻塞I/O的系统,一个请求对应一个线程,一旦有高并发的大量请求,就会有如下问题： 

1. 线程不够用, 就算使用了线程池复用线程也无济于事; 
2. 阻塞I/O模式下,会有大量的线程被**阻塞**,一直在等待数据,这个时候的线程被挂起,只能干等,CPU利用率很低,换句话说,系统的吞吐量差; 
3. 如果网络I/O堵塞或者有网络抖动或者网络故障等,线程的阻塞时间可能很长。整个系统也变的不可靠;



## 什么是NIO

​		java.nio全称java non-blocking IO（实际上是 new io），是指JDK 1.4 及以上版本里提供的新api（New IO） ，为所有的原始类型（boolean类型除外）提供[缓存](https://baike.baidu.com/item/缓存/100710)支持的数据容器，使用它可以提供非阻塞式的高伸缩性网络。

​		HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。



## IO和NIO的区别 

==**原有的 IO 是面向流的、阻塞的，NIO 则是面向块的、非阻塞的。**==

#### 怎么理解IO是面向流的、阻塞的

java1.4以前的io模型，一连接对一个线程。

**原始的IO是面向流的，不存在缓存的概念。Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区**

**Java IO的各种流是阻塞的，这意味着当一个线程调用read或 write方法时，该线程被==阻塞==，直到有一些数据被读取，或数据完全写入，该线程在此期间不能再干任何事情了。**

<img src="https://upload-images.jianshu.io/upload_images/13957164-549c6e2b66765298.png" alt="img" style="zoom:67%;" />

#### 怎么理解NIO是面向块的、非阻塞的

​		NIO是**==面向缓冲区==**的。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性。

​		Java NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此，一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。

通俗理解：NIO是可以做到用一个线程来处理多个操作的。假设有10000个请求过来,根据实际情况，可以分配50或者100个线程来处理。不像之前的阻塞IO那样，非得分配10000个。



# NIO的核心实现

在标准IO API中，你可以操作字节流和字符流，但在新IO中，你可以操作通道和缓冲，数据总是从通道被读取到缓冲中或者从缓冲写入到通道中。

NIO核心API Channel, Buffer, Selector

#### 通道Channel

NIO的通道类似于流，但有些区别如下：

1. 通道可以同时进行读写，而流只能读或者只能写

2. 通道可以实现异步读写数据

3. 通道可以从缓冲读数据，也可以写数据到缓冲: 



#### 缓存Buffer

缓冲区本质上是一个可以写入数据的内存块，然后可以再次读取，该对象提供了一组方法，可以更轻松地使用内存块，使用缓冲区读取和写入数据通常遵循以下四个步骤：

1. 写数据到缓冲区；

2. 调用buffer.flip()方法；

3. 从缓冲区中读取数据；

4. 调用buffer.clear()或buffer.compat()方法；

当向buffer写入数据时，buffer会记录下写了多少数据，一旦要读取数据，需要通过flip()方法将Buffer从写模式切换到读模式，在读模式下可以读取之前写入到buffer的所有数据，一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。

**Buffer在与Channel交互时，需要一些标志:**

buffer的大小/容量 - **Capacity**

作为一个内存块，Buffer有一个固定的大小值，用参数capacity表示。

当前读/写的位置 - **Position**

当写数据到缓冲时，position表示当前待写入的位置，position最大可为capacity – 1；当从缓冲读取数据时，position表示从当前位置读取。

信息末尾的位置 - **limit**

在写模式下，缓冲区的limit表示你最多能往Buffer里写多少数据； 写模式下，limit等于Buffer的capacity，意味着你还能从缓冲区获取多少数据。

下图展示了buffer中三个关键属性capacity，position以及limit在读写模式中的说明：

<img src="https://upload-images.jianshu.io/upload_images/13957164-8c4827d042813fce.png" alt="img" style="zoom:67%;" />

buffer中三个关键属性capacity，position以及limit在读写模式中的说明

缓冲区常用的操作

**向缓冲区写数据：**

1. 从Channel写到Buffer；

2. 通过Buffer的put方法写到Buffer中；

**从缓冲区读取数据：**

1. 从Buffer中读取数据到Channel；

2. 通过Buffer的get方法从Buffer中读取数据；

**flip方法：**

   将Buffer从写模式切换到读模式，将position值重置为0，limit的值设置为之前position的值；

**clear方法 vs compact方法：**

​    clear方法清空缓冲区；compact方法只会清空已读取的数据，而还未读取的数据继续保存在Buffer中；

#### Selector

一个组件，可以检测多个NIO channel，看看读或者写事件是否就绪。

多个Channel以事件的方式可以注册到同一个Selector，从而达到用一个线程处理多个请求成为可能。

<img src="https://upload-images.jianshu.io/upload_images/13957164-539fcf908e51b229.png" alt="img" style="zoom:50%;" />

<img src="https://upload-images.jianshu.io/upload_images/13957164-3d8041ee5b735b73.png" alt="img" style="zoom:67%;" />



首先，Requester方通过Selector.open()创建了一个Selector准备好了调度角色。

创建了**SocketChannel(ServerSocketChannel)** 并注册到Selector中，通过设置key（SelectionKey）告诉调度者所应该关注的连接请求。

阻塞，Selector阻塞在select操作中，如果发现有Channel发生连接请求，就会唤醒处理请求。

NIO同步非阻塞式IO

      对比BIO的同步阻塞IO操作，实际上NIO是同步非阻塞IO，一个线程在同步的进行轮询检查，Selector不断轮询注册在其上的Channel，某个Channel上面发生读写连接请求，这个Channel就处于就绪状态，被Selector轮询出来，然后通过SelectionKey可以获取就绪Channel的集合，进行后续的I/O操作。
    
       同步和异步说的是消息的通知机制，这个线程仍然要定时的读取stream，判断数据有没有准备好，client采用循环的方式去读取（线程自己去抓去信息），CPU被浪费。
    
     非阻塞：体现在，这个线程可以去干别的，不需要一直在这等着。Selector可以同时轮询多个Channel，因为JDK使用了epoll()代替传统的select实现，没有最大连接句柄限制。所以只需要一个线程负责Selector的轮询，就可以接入成千上万的客户端。




# AIO

是在NIO的基础上引入异步通道的概念，实现异步非阻塞式的IO处理。

 AIO不需要通过多路复用器对注册的通道进行轮询操作即可实现异步读写。什么意思呢？NIO采用轮询的方式，一直在轮询的询问stream中数据是否准备就绪，如果准备就绪发起处理。但是AIO就不需要了，AIO框架在windows下使用windows IOCP技术，在Linux下使用epoll多路复用IO技术模拟异步IO， 即：应用程序向操作系统注册IO监听，然后继续做自己的事情。操作系统发生IO事件，并且准备好数据后，在主动通知应用程序，触发相应的函数（这就是一种以订阅者模式进行的改造）。由于应用程序不是“轮询”方式而是订阅-通知方式，所以不再需要selector轮询，由channel通道直接到操作系统注册监听。



### NIO（AIO）中几个概念

+ 缓冲区 Buffer


NIO基于块进行数据处理，在NIO中所有数据的读取都是通过缓冲Buffer进行处理。

     具体的缓存区有这些：ByteBuffe、CharBuffer、 ShortBuffer、IntBuffer、LongBuffer、FloatBuffer、DoubleBuffer。他们实现了相同的接口：Buffer。

+ 通道 Channel

     对数据的读取和写入要通过Channel通道。通道不同于流的地方就是通道是双向的，用于读、写和同时读写操作。底层的操作系统的通道一般都是全双工的，全双工的Channel比流能更好的映射底层操作系统的API。

+ 多路复用器 Selector

Selector提供选择已经就绪的任务的能力：

      Selector轮询注册在其上的Channel，如果某个Channel发生读写请求并且Channel就处于就绪状态，会被Selector轮询出来，然后通过SelectionKey可以获取就绪Channel的集合，进行后续的I/O操作。（同步）
    
      一个Selector可以同时轮询多个Channel，因为JDK使用了epoll()代替传统的select实现，所以没有最大连接句柄1024/2048的限制。所以，只需要一个线程负责Selector的轮询，就可以接入成千上万的客户端。（非阻塞）



### NIO和AIO
+ NIO：会等数据准备好后，再交由应用进行处理，数据的读取/写入过程依然在应用线程中完成，只是将等待的时间剥离到单独的线程中去，节省了数据准备时间，因为多路复用机制，Selector会得到复用，对于那些读写过程时间长的，NIO就不太适合。

+ AIO：读完（内核内存拷贝到用户内存）了系统再通知应用，使用回调函数，进行业务处理，AIO能够胜任那些重量级，读写过程长的任务。