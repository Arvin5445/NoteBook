# 线程和进程区别

+ **进程：**在操作系统中能够独立运行，并且作为资源分配的基本单位。它表示运行中的程序。

+ **线程：**是进程中的一个实例，作为系统调度和分派的基本单位。是进程中的一段序列，能够完成进程中的一个功能。

1. 同一个进程可以包含多个线程，一个进程中至少包含一个线程，一个线程只能存在于一个进程中。

2. 同一个进程下的所有线程能够共享该进程下的资源。

   > 系统运行时会为每个进程分配不同的内存区域，但不会为线程分配内存。线程只能共享它所属进程的资源

3. 进程结束后，该进程下的所有线程将销毁，而一个线程的结束不会影响同一进程下的其他线程。

4. 线程是轻量级的进程，它的创建和销毁所需要的时间比进程小得多，所有操作系统的执行功能都是通过创建线程去完成的。

5. 线程在执行时是同步和互斥的，因为他们共享同一个进程下的资源。

6. 在操作系统中，进程是拥有系统资源的独立单元，它可以拥有自己的资源。一般而言，线程不能拥有自己的资源，但是它能够访问其隶属进程的资源。



# 内存交互协议

​		关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了以下8种操作来 完成，虚拟机实现时必须保证下面提及的每一种操作都是**原子**的、不可再分的（对于double 和long类型的变量来说，load、store、read和write操作在某些平台上允许有例外）。

> 允许虚拟机实现选择可以不保证64位数据类型的load、store、read和write这4个操作的 原子性，这点就是所谓的long和double的非原子性协定

+ lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。

+ unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放 后的变量才可以被其他线程锁定。

+ read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内 存中，以便随后的load动作使用。

+ load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工 作内存的变量副本中。

+ use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引 擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。

+ assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内 存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。

+ store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存 中，以便随后的write操作使用。

+ write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入 主内存的变量中。

​		如果要把一个变量从主内存复制到工作内存，那就要顺序地执行read和load操作，如果 要把变量从工作内存同步回主内存，就要顺序地执行store和write操作。注意，Java内存模型 只要求上述两个操作必须按顺序执行，而没有保证是连续执行。也就是说，read与load之 间、store与write之间是可插入其他指令的，如对主内存中的变量a、b进行访问时，一种可能 出现顺序是read a、read b、load b、load a。除此之外，Java内存模型还规定了在执行上述8种 基本操作时必须满足如下规则：

1. **不允许read和load、store和write操作之一单独出现**，即不允许一个变量从主内存读取了 但工作内存不接受，或者从工作内存发起回写了但主内存不接受的情况出现。
2. 不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。
3. 不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步 回主内存中。
4. 一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化 （load或assign）的变量，换句话说，就是对一个变量实施use、store操作之前，必须先执行 过了assign和load操作。
5. 一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线 程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。
6. 如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这 个变量前，需要重新执行load或assign操作初始化变量的值。
7. 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去 unlock一个被其他线程锁定住的变量。
8. 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操 作）。

​		这8种内存访问操作以及上述规则限定，再加上稍后介绍的对volatile的一些特殊规定， 就已经完全确定了Java程序中哪些内存访问操作在并发下是安全的。由于这种定义相当严谨 但又十分烦琐，实践起来很麻烦，所以在12.3.6节中笔者将介绍这种定义的一个等效判断原 则——**先行发生原则**，用来确定一个访问在并发环境下是否安全。



# volatile 与先行发生

**volatile 的作用：**

+ 保证此变量对所有线程的可见性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以 立即得知的。

+ 禁止指令重排序优化（指令重排序无法越过内存屏障）

> 除了volatile之外，Java还有两个关键字能实现可见性，即synchronized和final。

​		下面是Java内存模型下一些“天然的”先行发生关系，这些先行发生关系无须任何同步器 协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从 下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。

1. **程序次序规则（Program Order Rule）：**在一个线程内，按照程序代码顺序，书写在前面 的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序， 因为要考虑分支、循环等结构。
2. **管程锁定规则（Monitor Lock Rule）：**一个unlock操作先行发生于后面对同一个锁的lock 操作。这里必须强调的是同一个锁，而“后面”是指时间上的先后顺序。
3. **volatile变量规则（Volatile Variable Rule）：**对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序。
4. **线程启动规则（Thread Start Rule）：**Thread对象的start（）方法先行发生于此线程的每 一个动作。
5. **线程终止规则（Thread Termination Rule）：**线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join（）方法结束、Thread.isAlive（）的返回值等手段检测到线程已经终止执行。
6. **线程中断规则（Thread Interruption Rule）：**对线程interrupt（）方法的调用先行发生于被 中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted（）方法检测到是否有中断发生。
7. **对象终结规则（Finalizer Rule）：**一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize（）方法的开始。
8. **传递性（Transitivity）：**如果操作A先行发生于操作B，操作B先行发生于操作C，那就 可以得出操作A先行发生于操作C的结论。





# 线程五种状态

​		Java语言定义了5种线程状态，在任意一个时间点，一个线程只能有且只有其中的一种 状态，这5种状态分别如下。

1. **新建（New）：**创建后尚未启动的线程处于这种状态。

2. **运行（Runable）：**Runable包括了操作系统线程状态中的Running和Ready，也就是处于此 状态的线程有可能正在执行，也有可能正在等待着CPU为它分配执行时间。 

3. **无限期等待（Waiting）：**处于这种状态的线程不会被分配CPU执行时间，它们要等待被 其他线程显式地唤醒。以下方法会让线程陷入无限期的等待状态：

   + 没有设置Timeout参数的Object.wait（）方法。

     [为什么wait()方法要放在同步块](https://www.cnblogs.com/Joy-Hu/p/10693969.html)

   + 没有设置Timeout参数的Thread.join（）方法。

   + LockSupport.park（）方法。

4. **限期等待（Timed Waiting）：**处于这种状态的线程也不会被分配CPU执行时间，不过无 须等待被其他线程显式地唤醒，在一定时间之后它们会由系统自动唤醒。以下方法会让线程 进入限期等待状态

   + Thread.sleep（）方法。
   + 设置了Timeout参数的Object.wait（）方法。
   + 设置了Timeout参数的Thread.join（）方法。
   + LockSupport.parkNanos（）方法。
   + LockSupport.parkUntil（）方法。

5. **阻塞（Blocked）：**线程被阻塞了，**“阻塞状态”与“等待状态”的区别是：“阻塞状态”在等待着获取到一个排他锁**，这个事件将在另外一个线程放弃这个锁的时候发生；而“等待状 态”则是在等待一段时间，或者唤醒动作的发生。在程序等待进入同步区域的时候，线程将 进入这种状态。

6. **结束（Terminated）：**已终止线程的线程状态，线程已经结束执行。

<img src="/Users/arvin/Library/Application Support/typora-user-images/image-20200316155843233.png" alt="image-20200316155843233" style="zoom: 50%;" />





# 互斥同步

### synchronized（管程）

​		synchronized关键字经过编译之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java程序中的 synchronized明确指定了对象参数，那就是这个对象的reference；如果没有明确指定，那就根 据synchronized修饰的是实例方法还是类方法，去取对应的对象实例或Class对象来作为锁对象。

​		在执行monitorenter指令时，首先要尝试获取对象的锁。如果这 个对象没被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加1，相应的，在 执行monitorexit指令时会将锁计数器减1，当计数器为0时，锁就被释放。如果获取对象锁失 败，那当前线程就要阻塞等待，直到对象锁被另外一个线程释放为止。

​		synchronized同步块对同一条线程来说是**可重入**的。



### ReentrantLock（java.util.concurrent）

​		ReentrantLock与synchronized很相似，他们都 具备一样的线程**重入**特性，只是代码写法上有点区别，一个表现为**API层面（AQS）**的互斥锁 （`lock()`和 `unlock()` 方法配合 `try/finally` 语句块来完成），另一个表现为**原生语法层面**的互斥锁。不过，相比synchronized,ReentrantLock增加了一些高级功能，主要有以下3项：

+ 等待可中断  超时中断`tryLock()`   interrupt中断 `lockInterruptibly`
+ 可实现公平锁 `new ReentrantLock(false)`
+ 以及锁可以绑定多个条件 `condition`



# 非阻塞同步

### CAS 比较并交换（Compare-and-Swap）

​		在 JDK 1.5之后，Java程序中才可以使用CAS操作，该操作由 `sun.misc.Unsafe` 类里面的 `compareAndSwapInt()` 和 `compareAndSwapLong()` 等几个方法包装提供，虚拟机在内部对 这些方法做了特殊处理，即时编译出来的结果就是一条平台相关的处理器CAS指令，没有方 法调用的过程，或者可以认为是无条件内联进去了。

​		CAS指令需要有3个操作数，分别是内存位置（在Java中可以简单理解为变量的内存地址，用V表示）、旧的预期值（用A表示）和新值（用B表示）。CAS指令执行时，当且仅当V符合旧预期值A时，处理器用新值B更新V的值，否则它就不执行更新，但是无论是否更新 了V的值，都会返回V的旧值，上述的处理过程是一个**原子操作**。

### “ABA” 问题

​		J.U.C包为了解决这个问题， 提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的**版本**来保证CAS的正确性。不过目前来说这个类比较“鸡肋”，大部分情况下ABA问题不会影响程 序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更高效。

### 无同步方案

+ 可重入代码（Reentrant Code）

  ​		不依赖存储在堆上的数据和公用的系统资源、用到 的状态量都由参数中传入、不调用非可重入的方法，返回结果是可以预测的，只要输入了相同的数 据，就都能返回相同的结果

+ 线程本地存储（Thread Local Storage）

  ​		如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行？如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内 `java.lang.ThreadLocal` ，这样，无须同步也能保证线程之间不出 现数据争用的问题。

  > 符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费 者”模式）都会将产品的**消费过程尽量在一个线程中消费完**，其中最重要的一个应用实例就 是经典Web交互模型中的**“一个请求对应一个服务器线程”**（Thread-per-Request）的处理方 式，这种处理方式的广泛应用使得很多Web服务端应用都可以使用线程本地存储来解决线程 安全问题。



# 锁优化

适应性自旋（Adaptive Spinning）、锁消除 （Lock Elimination）、锁粗化（Lock Coarsening）、轻量级锁（Lightweight Locking）和偏向锁（Biased Locking）

### 轻量级锁

​		在代码进 入同步块的时候，如果此同步对象没有被锁定（锁标志位为“01”状态），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝（官方把这份拷贝加了一个Displaced前缀，即Displaced Mark Word），这时候线 程堆栈与对象头的状态如图13-3所示。

​		然后，虚拟机将使用**CAS**操作尝试将对象的Mark Word更新为指向Lock Record的指针。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标 志位（Mark Word的最后2bit）将转变为“00”，即表示此对象处于轻量级锁定状态，这时候线 程堆栈与对象头的状态如图13-4所示。

<img src="/Users/arvin/Library/Application Support/typora-user-images/image-20200316234329830.png" alt="image-20200316234329830" style="zoom:50%;" />

​		如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果只说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否 则说明这个锁对象已经被其他线程抢占了。如果有两条以上的线程争用同一个锁，那轻量级 锁就不再有效，要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指 向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。

​		上面描述的是轻量级锁的加锁过程，它的解锁过程也是通过CAS操作来进行的，如果对 象的Mark Word仍然指向着线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中 复制的Displaced Mark Word替换回来，如果替换成功，整个同步过程就完成了。如果替换失 败，说明有其他线程尝试过获取该锁，那就要在释放锁的同时，唤醒被挂起的线程。

​		轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用CAS操作避免了使用互斥 量的开销，但如果存在锁竞争，除了互斥量的开销外，还额外发生了CAS操作，因此在有竞 争的情况下，轻量级锁会比传统的重量级锁更慢。



### 偏向锁

​		偏向锁也是JDK 1.6中引入的一项锁优化，它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都不做了。

​		偏向锁会偏向于第一个获得 它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程 将永远不需要再进行同步。

​		如果读者读懂了前面轻量级锁中关于对象头Mark Word与线程之间的操作过程，那偏向 锁的原理理解起来就会很简单。假设当前虚拟机启用了偏向锁（启用参数-XX： +UseBiasedLocking，这是JDK 1.6的默认值），那么，当锁对象第一次被线程获取的时候， 虚拟机将会把对象头中的标志位设为“01”，即偏向模式。同时使用CAS操作把获取到这个锁 的线程的ID记录在对象的Mark Word之中，如果CAS操作成功，持有偏向锁的线程以后每次 进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作（例如Locking、Unlocking 及对Mark Word的Update等）。

​		当有另外一个线程去尝试获取这个锁时，偏向模式就宣告结束。根据锁对象目前是否处 于被锁定的状态，撤销偏向（Revoke Bias）后恢复到未锁定（标志位为“01”）或轻量级锁定 （标志位为“00”）的状态，后续的同步操作就如上面介绍的轻量级锁那样执行。偏向锁、轻 量级锁的状态转化及对象Mark Word的关系如图13-5所示。





# 锁的种类



## 1. 乐观锁



## 2. 悲观锁



## 3. 读写锁

**ReentrantLock**

ReentrantReadWriteLock.WriteLock writeLock()

ReentrantReadWriteLock.ReadLock  readLock()



**StampedLock**

long readLock()

long writeLock()

void unlockWrite(long stamp)

void unlockRead(long stamp)



## 4. 自旋锁

获取锁失败时不立刻阻塞自己

而是进入一个忙自旋（10次），还是获取失败再阻塞



## 5. 可重入锁

[可重入锁](#ReentrantLock（java.util.concurrent）)



## 6. 偏向锁

[偏向锁](#偏向锁)



## 7. 轻量级锁

[轻量级锁](#轻量级锁)



## 8. 公平锁



## 9. 非公平锁







# 死锁

**只有以下这四个条件都发生时才会出现死锁：**

1. 互斥，共享资源 X 和 Y 只能被一个线程占用；
2. 占有且等待，线程 T1 已经取得共享资源 X，在等待共享资源 Y 的时候，不释放共享资源 X；
3. 不可抢占，其他线程不能强行抢占线程 T1 占有的资源；

4. 循环等待，线程 T1 等待线程 T2 占有的资源，线程 T2 等待线程 T1 占有的资源，就是循环等待。

**破坏条件来规避死锁：**

1. 互斥这个条件我们没有办法破坏，因为我们用锁为的就是互斥。
2. 对于“占用且等待”这个条件，一次性申请所有的资源。
3. 对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可 以主动释放它占有的资源。
4. 对于“循环等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性 顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后自然就不 存在循环了。





# AQS

**AQS原理**
AQS：AbstractQuenedSynchronizer抽象的队列式同步器。是除了java自带的synchronized关键字之外的锁机制。
AbstractQueuedSynchronizer）

**AQS的核心思想**是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并将共享资源设置为锁定状态，如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。
CLH（Craig，Landin，and Hagersten）队列是一个虚拟的双向队列，虚拟的双向队列即不存在队列实例，仅存在节点之间的关联关系。
**AQS是将每一条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node），来实现锁的分配。**

用大白话来说，AQS就是基于CLH队列，用volatile修饰共享变量state，线程通过CAS去改变状态符，成功则获取锁成功，失败则进入等待队列，等待被唤醒。

**注意：AQS是==自旋锁==：**在等待唤醒的时候，经常会使用自旋（while(!cas())）的方式，不停地尝试获取锁，直到被其他线程获取成功

**实现了AQS的锁有：自旋锁、互斥锁、读锁写锁、条件产量、信号量、栅栏都是AQS的衍生物**
AQS实现的具体方式如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20181128142923147.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L211bGluc2VuNzc=,size_16,color_FFFFFF,t_70)
如图示，AQS维护了一个volatile int state和一个FIFO线程等待队列，多线程争用资源被阻塞的时候就会进入这个队列。state就是共享资源，其访问方式有如下三种：
getState();setState();compareAndSetState();

AQS 定义了两种资源共享方式：
1.**Exclusive**：独占，只有一个线程能执行，如ReentrantLock
2.**Share**：共享，多个线程可以同时执行，如Semaphore、CountDownLatch、ReadWriteLock，CyclicBarrier

不同的自定义的同步器争用共享资源的方式也不同。

**AQS底层使用了模板方法模式**

同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）：

1. 使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放）
2. 将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。
   这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用。

自定义同步器在实现的时候只需要实现共享资源state的获取和释放方式即可，至于具体线程等待队列的维护，AQS已经在顶层实现好了。自定义同步器实现的时候主要实现下面几种方法：

+ isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。
+ tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。
+ tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。
+ tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
+ tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。

> **ReentrantLock**为例，（可重入独占式锁）：state初始化为0，表示未锁定状态，A线程lock()时，会调用tryAcquire()独占锁并将state+1.之后其他线程再想tryAcquire的时候就会失败，直到A线程unlock（）到state=0为止，其他线程才有机会获取该锁。A释放锁之前，自己也是可以重复获取此锁（state累加），这就是可重入的概念。
> 注意：获取多少次锁就要释放多少次锁，保证state是能回到零态的。

> **CountDownLatch**为例，任务分N个子线程去执行，state就初始化 为N，N个线程并行执行，每个线程执行完之后countDown（）一次，state就会CAS减一。当N子线程全部执行完毕，state=0，会unpark()主调用线程，主调用线程就会从await()函数返回，继续之后的动作。

一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时**实现独占和共享两种方式，如ReentrantReadWriteLock。**
　在acquire() acquireShared()两种方式下，线程在等待队列中都是忽略中断的，**acquireInterruptibly()/acquireSharedInterruptibly()是支持响应中断**的。

**AQS的简单应用**
Mutex：不可重入互斥锁，锁资源（state）只有两种状态：0：未被锁定；1：锁定。

```java
class Mutex implements Lock, java.io.Serializable {
    // 自定义同步器
    private static class Sync extends AbstractQueuedSynchronizer {
        // 判断是否锁定状态
        @Override
        protected boolean isHeldExclusively() {
            return getState() == 1;
        }

        // 尝试获取资源，立即返回。成功则返回true，否则false。
        @Override
        public boolean tryAcquire(int acquires) {
            assert acquires == 1; // 这里限定只能为1个量
            if (compareAndSetState(0, 1)) {//state为0才设置为1，不可重入！
                setExclusiveOwnerThread(Thread.currentThread());//设置为当前线程独占资源
                return true;
            }
            return false;
        }

        // 尝试释放资源，立即返回。成功则为true，否则false。
        @Override
        protected boolean tryRelease(int releases) {
            assert releases == 1; // 限定为1个量
            if (getState() == 0)//既然来释放，那肯定就是已占有状态了。只是为了保险，多层判断！
                throw new IllegalMonitorStateException();
            setExclusiveOwnerThread(null);
            setState(0);//释放资源，放弃占有状态
            return true;
        }
    }

    // 真正同步类的实现都依赖继承于AQS的自定义同步器！
    private final Sync sync = new Sync();

    //lock<-->acquire。两者语义一样：获取资源，即便等待，直到成功才返回。
    public void lock() {
        sync.acquire(1);
    }

    //tryLock<-->tryAcquire。两者语义一样：尝试获取资源，要求立即返回。成功则为true，失败则为false。
    public boolean tryLock() {
        return sync.tryAcquire(1);
    }

    //unlock<-->release。两者语文一样：释放资源。
    public void unlock() {
        sync.release(1);
    }

    //锁是否占有状态
    public boolean isLocked() {
        return sync.isHeldExclusively();
    }
}
```





# CAS

[CAS](#CAS 比较并交换（Compare-and-Swap）)



# 线程池

**为什么需要线程池？**

​		创建对象，仅仅是在JVM的堆里分配一块内存而已；而创建一个线程，却需要调用操作系统**内核**的API**（用户态 -> 内核态）**，然后操作系统要为线程分配一系列的资源，这个成本就很高了，所以 线程是一个重量级的对象，应该避免频繁创建和销毁。

==**线程池是一种生产者 - 消费者模式（阻塞队列）**==

核心类 `ThreadPoolExecutor`	`ThreadPoolExecutor` 实现了 `ExecutorService` 接口

工厂类 `Executors`

​		不建议使用 `Executors` 的最重要的原因是：`Executors` 提供的很多方法默认使用的都是无界的 `LinkedBlockingQueue`，**无界队列**很容易导致OOM。

​		通过 `ThreadPoolExecutor` 对象的 `execute()` 方法提交任务时， 如果任务在执行的过程中出现运行时异常，会导致执行任务的线程终止；最致命的是任务虽然异常了，但是你却获取不到任何通知。虽然线程池提供了很多用于异常处理的方法，但是最稳妥和简单的方案还是捕获所有异常并按需处理

**参数**

+ **corePoolSize：**表示线程池保有的最小线程数。有些项目很闲，但是也不能把人都撤了，至少要留 corePoolSize个人坚守阵地。

+ **maximumPoolSize：**表示线程池创建的最大线程数。当项目很忙时，就需要加人，但是也不能无限制地 加，最多就加到maximumPoolSize个人。当项目闲下来时，就要撤人了，最多能撤到corePoolSize个人。

+ **keepAliveTime & unit：**上面提到项目根据忙闲来增减人员，那在编程世界里，如何定义忙和闲呢？很简 单，一个线程如果在一段时间内，都没有执行任务，说明很闲，keepAliveTime 和 unit 就是用来定义这 个“一段时间”的参数。也就是说，如果一个线程空闲了keepAliveTime & unit这么久，而且线程池 的线程数大于 corePoolSize ，那么这个空闲的线程就要被回收了。

+ **workQueue：**工作队列，和上面示例代码的工作队列同义。
+ **threadFactory：**通过这个参数你可以自定义如何创建线程，例如你可以给线程指定一个有意义的名字。
+ **handler：**拒绝策略。如果线程池中所有的线程都在忙碌，并且工作队列也满了（前提是工作队列是有界队列），此时提交任务，线程池就会拒绝接收。
  +  CallerRunsPolicy：提交任务的线程自己去执行该任务。
  + AbortPolicy：默认的拒绝策略，会throws RejectedExecutionException。
  + DiscardPolicy：直接丢弃任务，没有任何异常抛出。
  + DiscardOldestPolicy：丢弃最老的任务，其实就是把最早进入工作队列的任务丢弃，然后把新任务加入 到工作队列。

> Java在1.6版本还增加了 allowCoreThreadTimeOut(boolean value) 方法，它可以让所有线程都支持超时，这 意味着如果项目很闲，就会将项目组的成员都撤走。



```java
// worker = 忙线程（Runnable AQS）Run() { 循环从 workQueue 中取出任务，并执行它的 run() 方法 }
public void execute(Runnable command) {
        if (command == null)
            throw new NullPointerException();
        int c = ctl.get();
    
    	// worker数 < corePoolSize ：直接创建 worker 来运行新任务
        if (workerCountOf(c) < corePoolSize) {
            if (addWorker(command, true))
                return;
            c = ctl.get();
        }
    
    	// 否则把新任务加入 workQueue
        if (isRunning(c) && workQueue.offer(command)) {
            int recheck = ctl.get();
            if (! isRunning(recheck) && remove(command))
                reject(command);
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
    	
    	// 因为 workQueue 满而加入失败，则执行拒绝策略
        else if (!addWorker(command, false))
            reject(command);
    }
```





# 单例

```java
public class Singleton {
    private Singleton() {
    }
    //基于CAS的单例模式
    private static final AtomicReference<Singleton> INSTANCE = new AtomicReference<Singleton>();

    public static final Singleton getInstance() {
        for (; ; ) {
            Singleton current = INSTANCE.get();
            if (current != null) {
                return current;
            }
            //高并发的场景下，可能会创建多个对象，但是最终只有一个会被使用，其它的会被丢弃
            current = new Service();
            System.out.println(current);
            if (INSTANCE.compareAndSet(null, current)) {
                return current;
            }
        }
    }
}
```

```java
//基于双锁检测的单例模式
public class Singleton {  
    private volatile static Singleton singleton;  
    private Singleton () {}  
    public static Singleton getSingleton() {  
    if (singleton == null) {  
        synchronized (Singleton.class) {  
        if (singleton == null) {  
            singleton = new Singleton();  
        }  
        }  
    }  
    return singleton;  
    }  
}
```

